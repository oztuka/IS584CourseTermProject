{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1aZkLHfYpDkI9Qn3DqsD6TMiQWZ4zxiSX",
      "authorship_tag": "ABX9TyNiXu2ZZ3wgM+ClI6887ZUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oztuka/IS584CourseTermProject/blob/main/notebooks/Preliminary_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS 584: Deep Learning for Text Analytics"
      ],
      "metadata": {
        "id": "wWNCF82uOL1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term Project\n",
        "\n",
        "**Preliminary Results and Benchmarking**\n",
        "\n",
        "**Özkan Tuğberk Kartal**\n",
        "\n",
        "**2481117**\n",
        "\n",
        "The following codes are written regarding Creating Dataset and Preliminary Results and Benchmarking:"
      ],
      "metadata": {
        "id": "9AvvVUanRq8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Dataset"
      ],
      "metadata": {
        "id": "qXtCbKdeH9ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "def natural_sort_key(s):\n",
        "    return [int(text) if text.isdigit() else text.lower()\n",
        "            for text in re.split(r'(\\d+)', s)]\n",
        "\n",
        "def get_pandas_data_from(filenames):\n",
        "  data_list = []\n",
        "  for filename in filenames:\n",
        "    try:\n",
        "      with open(filename, 'r') as file:\n",
        "        # json_normalize is used to flatten the nested dicts\n",
        "        # this will increase the number of total columns of data\n",
        "        data_list.append(pd.json_normalize(json.load(file)))\n",
        "    except: # ignore erroneous json file data\n",
        "      pass\n",
        "  return pd.concat(data_list, ignore_index=True)\n",
        "\n",
        "print(\"pandas.__version__: \" + pd.__version__)\n",
        "print(\"gdown.__version__: \" + gdown.__version__)\n",
        "print(\"re.__version__: \" + re.__version__)\n",
        "print(\"json.__version__: \" + json.__version__)\n",
        "\n",
        "data_zip_download_file_url = f\"https://drive.google.com/uc?export=download&id=1nJdljy468roUcKLbVwWUhMs7teirah75\"\n",
        "\n",
        "output_zip_file_name = \"dataset.zip\"\n",
        "\n",
        "gdown.download(data_zip_download_file_url, output_zip_file_name, quiet = False)\n",
        "\n",
        "# extract ZIP file\n",
        "with zipfile.ZipFile(output_zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojqQ92dUCC22",
        "outputId": "d805005e-e1dc-438e-91bb-e47fdd83584c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas.__version__: 2.2.2\n",
            "gdown.__version__: 5.2.0\n",
            "re.__version__: 2.2.1\n",
            "json.__version__: 2.0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1nJdljy468roUcKLbVwWUhMs7teirah75\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1nJdljy468roUcKLbVwWUhMs7teirah75&confirm=t&uuid=de0c44b5-028d-44b4-9840-082f0b22ed9c\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 235M/235M [00:05<00:00, 45.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get root_folder\n",
        "root_folder = Path(\"dataset/dataset\")\n",
        "\n",
        "ICLR_content_files = []\n",
        "ICLR_paper_files = []\n",
        "ICLR_review_files = []\n",
        "NIPS_content_files = []\n",
        "NIPS_paper_files = []\n",
        "NIPS_review_files = []\n",
        "\n",
        "# Iterate over all subdirectories and files\n",
        "for file in root_folder.rglob('*content.json'):\n",
        "    # Check if the word \"ICLR\" is in the file name\n",
        "    if 'ICLR' in file.name:\n",
        "        ICLR_content_files.append(str(file.parent) + \"/\" + file.name)\n",
        "    elif 'NIPS' in file.name:\n",
        "        NIPS_content_files.append(str(file.parent) + \"/\" + file.name)\n",
        "for file in root_folder.rglob('*paper.json'):\n",
        "    # Check if the word \"ICLR\" is in the file name\n",
        "    if 'ICLR' in file.name:\n",
        "        ICLR_paper_files.append(str(file.parent) + \"/\" + file.name)\n",
        "    elif 'NIPS' in file.name:\n",
        "        NIPS_paper_files.append(str(file.parent) + \"/\" + file.name)\n",
        "for file in root_folder.rglob('*review.json'):\n",
        "    # Check if the word \"ICLR\" is in the file name\n",
        "    if 'ICLR' in file.name:\n",
        "        ICLR_review_files.append(str(file.parent) + \"/\" + file.name)\n",
        "    elif 'NIPS' in file.name:\n",
        "        NIPS_review_files.append(str(file.parent) + \"/\" + file.name)\n",
        "\n",
        "ICLR_content_files = sorted(ICLR_content_files, key = natural_sort_key)\n",
        "ICLR_paper_files = sorted(ICLR_paper_files, key = natural_sort_key)\n",
        "ICLR_review_files = sorted(ICLR_review_files, key = natural_sort_key)\n",
        "NIPS_content_files = sorted(NIPS_content_files, key = natural_sort_key)\n",
        "NIPS_paper_files = sorted(NIPS_paper_files, key = natural_sort_key)\n",
        "NIPS_review_files = sorted(NIPS_review_files, key = natural_sort_key)\n",
        "\n",
        "ICLR_content_data = get_pandas_data_from(ICLR_content_files)\n",
        "ICLR_paper_data = get_pandas_data_from(ICLR_paper_files)\n",
        "ICLR_review_data = get_pandas_data_from(ICLR_review_files)\n",
        "NIPS_content_data = get_pandas_data_from(NIPS_content_files)\n",
        "NIPS_paper_data = get_pandas_data_from(NIPS_paper_files)\n",
        "NIPS_review_data = get_pandas_data_from(NIPS_review_files)\n",
        "\n",
        "# basing upon id of the items, merge each ICLR and NIPS data into one by replacing\n",
        "# missing column values with NaN by using 'how' = 'outer'\n",
        "ICLR_data = pd.merge(pd.merge(ICLR_content_data, ICLR_paper_data, on='id', how='outer'), ICLR_review_data, on='id', how='outer')\n",
        "NIPS_data = pd.merge(pd.merge(NIPS_content_data, NIPS_paper_data, on='id', how='outer'), NIPS_review_data, on='id', how='outer')\n",
        "\n",
        "# concatenate ICLR_data and NIPS_data\n",
        "data = pd.concat([ICLR_data, NIPS_data], ignore_index=True)\n",
        "\n",
        "# ICLR_data, NIPS_data and data can be processed in the future\n",
        "\n",
        "print(\"ICLR_content_files count: \" + str(len(ICLR_content_files)))\n",
        "print(\"ICLR_content_data.shape: \" + str(ICLR_content_data.shape))\n",
        "print(\"ICLR_content_data.columns: \" + str(ICLR_content_data.columns))\n",
        "print(\" \")\n",
        "print(\"ICLR_paper_files count: \" + str(len(ICLR_paper_files)))\n",
        "print(\"ICLR_paper_data.shape: \" + str(ICLR_paper_data.shape))\n",
        "print(\"ICLR_paper_data.columns: \" + str(ICLR_paper_data.columns))\n",
        "print(\" \")\n",
        "print(\"ICLR_review_files count: \" + str(len(ICLR_review_files)))\n",
        "print(\"ICLR_review_data.shape: \" + str(ICLR_review_data.shape))\n",
        "print(\"ICLR_review_data.columns: \" + str(ICLR_review_data.columns))\n",
        "print(\" \")\n",
        "print(\"ICLR_data.shape: \" + str(ICLR_data.shape))\n",
        "print(\"ICLR_data.columns: \" + str(ICLR_data.columns))\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "\n",
        "print(\"NIPS_content_files count: \" + str(len(NIPS_content_files)))\n",
        "print(\"NIPS_content_data.shape: \" + str(NIPS_content_data.shape))\n",
        "print(\"NIPS_content_data.columns: \" + str(NIPS_content_data.columns))\n",
        "print(\" \")\n",
        "print(\"NIPS_paper_files count: \" + str(len(NIPS_paper_files)))\n",
        "print(\"NIPS_paper_data.shape: \" + str(NIPS_paper_data.shape))\n",
        "print(\"NIPS_paper_data.columns: \" + str(NIPS_paper_data.columns))\n",
        "print(\" \")\n",
        "print(\"NIPS_review_files count: \" + str(len(NIPS_review_files)))\n",
        "print(\"NIPS_review_data.shape: \" + str(NIPS_review_data.shape))\n",
        "print(\"NIPS_review_data.columns: \" + str(NIPS_review_data.columns))\n",
        "print(\" \")\n",
        "print(\"NIPS_data.shape: \" + str(NIPS_data.shape))\n",
        "print(\"NIPS_data.columns: \" + str(NIPS_data.columns))\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "\n",
        "print(\"data.shape: \" + str(data.shape))\n",
        "print(\"data.columns: \" + str(data.columns))\n",
        "print(\" \")\n",
        "print(\" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Utfpjglgnjr",
        "outputId": "da97c76d-5553-4f6a-da37-360639b1c5ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ICLR_content_files count: 5171\n",
            "ICLR_content_data.shape: (5171, 12)\n",
            "ICLR_content_data.columns: Index(['name', 'id', 'metadata.source', 'metadata.title', 'metadata.authors',\n",
            "       'metadata.emails', 'metadata.sections', 'metadata.references',\n",
            "       'metadata.referenceMentions', 'metadata.year', 'metadata.abstractText',\n",
            "       'metadata.creator'],\n",
            "      dtype='object')\n",
            " \n",
            "ICLR_paper_files count: 5192\n",
            "ICLR_paper_data.shape: (5192, 8)\n",
            "ICLR_paper_data.columns: Index(['id', 'conference', 'decision', 'url', 'hasContent', 'hasReview',\n",
            "       'title', 'authors'],\n",
            "      dtype='object')\n",
            " \n",
            "ICLR_review_files count: 5178\n",
            "ICLR_review_data.shape: (5178, 3)\n",
            "ICLR_review_data.columns: Index(['id', 'reviews', 'metaReview'], dtype='object')\n",
            " \n",
            "ICLR_data.shape: (5194, 21)\n",
            "ICLR_data.columns: Index(['name', 'id', 'metadata.source', 'metadata.title', 'metadata.authors',\n",
            "       'metadata.emails', 'metadata.sections', 'metadata.references',\n",
            "       'metadata.referenceMentions', 'metadata.year', 'metadata.abstractText',\n",
            "       'metadata.creator', 'conference', 'decision', 'url', 'hasContent',\n",
            "       'hasReview', 'title', 'authors', 'reviews', 'metaReview'],\n",
            "      dtype='object')\n",
            " \n",
            " \n",
            "NIPS_content_files count: 3684\n",
            "NIPS_content_data.shape: (3684, 12)\n",
            "NIPS_content_data.columns: Index(['name', 'id', 'metadata.source', 'metadata.title', 'metadata.authors',\n",
            "       'metadata.emails', 'metadata.sections', 'metadata.references',\n",
            "       'metadata.referenceMentions', 'metadata.year', 'metadata.abstractText',\n",
            "       'metadata.creator'],\n",
            "      dtype='object')\n",
            " \n",
            "NIPS_paper_files count: 3685\n",
            "NIPS_paper_data.shape: (3685, 8)\n",
            "NIPS_paper_data.columns: Index(['id', 'conference', 'decision', 'url', 'hasContent', 'hasReview',\n",
            "       'title', 'authors'],\n",
            "      dtype='object')\n",
            " \n",
            "NIPS_review_files count: 3602\n",
            "NIPS_review_data.shape: (3602, 3)\n",
            "NIPS_review_data.columns: Index(['id', 'reviews', 'metaReview'], dtype='object')\n",
            " \n",
            "NIPS_data.shape: (3934, 21)\n",
            "NIPS_data.columns: Index(['name', 'id', 'metadata.source', 'metadata.title', 'metadata.authors',\n",
            "       'metadata.emails', 'metadata.sections', 'metadata.references',\n",
            "       'metadata.referenceMentions', 'metadata.year', 'metadata.abstractText',\n",
            "       'metadata.creator', 'conference', 'decision', 'url', 'hasContent',\n",
            "       'hasReview', 'title', 'authors', 'reviews', 'metaReview'],\n",
            "      dtype='object')\n",
            " \n",
            " \n",
            "data.shape: (9128, 21)\n",
            "data.columns: Index(['name', 'id', 'metadata.source', 'metadata.title', 'metadata.authors',\n",
            "       'metadata.emails', 'metadata.sections', 'metadata.references',\n",
            "       'metadata.referenceMentions', 'metadata.year', 'metadata.abstractText',\n",
            "       'metadata.creator', 'conference', 'decision', 'url', 'hasContent',\n",
            "       'hasReview', 'title', 'authors', 'reviews', 'metaReview'],\n",
            "      dtype='object')\n",
            " \n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ICLR data first ten rows are \")\n",
        "print(ICLR_data.head(10))\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "\n",
        "print(\"NIPS data first ten rows are \")\n",
        "print(NIPS_data.head(10))\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "\n",
        "# os.makedirs('histograms', exist_ok=True)\n",
        "\n",
        "for col_index in range(len(data.columns)):\n",
        "  try:\n",
        "    unique_values_if_applicable = data[data.columns[col_index]].unique()\n",
        "  except:\n",
        "    print(\"For the column '\" + str(data.columns[col_index]) + \"', data are given in the list format\")\n",
        "    print(\" \")\n",
        "    print(\" \")\n",
        "    print(\" \")\n",
        "    print(\" \")\n",
        "    print(\" \")\n",
        "    continue\n",
        "  print(\"For the column '\" + str(data.columns[col_index]) + \"', there are \" + str(len(unique_values_if_applicable))+ \" unique values which are given by\")\n",
        "  print(unique_values_if_applicable)\n",
        "  value_counts = data[data.columns[col_index]].value_counts()\n",
        "  occuring_more_than_once = value_counts[value_counts > 1]\n",
        "  if len(unique_values_if_applicable) < 50:\n",
        "    print(\" \")\n",
        "    print(\" and histogram of this column is given by \")\n",
        "    ax = value_counts.plot(kind='bar', xlabel=str(data.columns[col_index]), ylabel='Count', rot=90)\n",
        "    plt.tight_layout()\n",
        "    fig = ax.get_figure()\n",
        "    # fig.savefig('histograms/' + str(data.columns[col_index]).replace(\".\", \"_\") + '_histogram.eps', format='eps', dpi=300)\n",
        "    # fig.savefig('histograms/' + str(data.columns[col_index]).replace(\".\", \"_\") + '_histogram.jpeg', format='jpeg', dpi=300)\n",
        "    # fig.savefig('histograms/' + str(data.columns[col_index]).replace(\".\", \"_\") + '_histogram.svg', format='svg', dpi=300)\n",
        "    plt.show()\n",
        "  elif len(occuring_more_than_once) > 0:\n",
        "    print(\" \")\n",
        "    print(\" and the following unique values occur more than once\")\n",
        "    print(occuring_more_than_once)\n",
        "  print(\" \")\n",
        "  print(\" \")\n",
        "  print(\" \")\n",
        "  print(\" \")\n",
        "  print(\" \")\n",
        "\n",
        "# shutil.make_archive('histograms', 'zip', 'histograms')\n",
        "\n",
        "# ICLR_data.to_pickle('ICLR_data.pkl')\n",
        "\n",
        "# NIPS_data.to_pickle('NIPS_data.pkl')\n",
        "\n",
        "# data.to_pickle('all_data.pkl')\n",
        "\n",
        "# ICLR_data.to_csv('ICLR_data.csv')\n",
        "\n",
        "# NIPS_data.to_csv('NIPS_data.csv')\n",
        "\n",
        "# data.to_csv('all_data.csv')\n",
        "\n",
        "ICLR_data_serialized = ICLR_data.applymap(lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x)\n",
        "\n",
        "NIPS_data_serialized = NIPS_data.applymap(lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x)\n",
        "\n",
        "data_serialized = data.applymap(lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x)\n",
        "\n",
        "ILLEGAL_CHARACTERS_RE = re.compile(r'[\\x00-\\x1F]')\n",
        "\n",
        "def remove_illegal_chars(value):\n",
        "    if isinstance(value, str):\n",
        "        return ILLEGAL_CHARACTERS_RE.sub('', value)\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "ICLR_data_clean = ICLR_data_serialized.applymap(remove_illegal_chars)\n",
        "NIPS_data_clean = NIPS_data_serialized.applymap(remove_illegal_chars)\n",
        "data_clean = data_serialized.applymap(remove_illegal_chars)\n",
        "\n",
        "# ICLR_data_clean.to_excel('ICLR_data.xlsx')\n",
        "\n",
        "# NIPS_data_clean.to_excel('NIPS_data.xlsx')\n",
        "\n",
        "# data_clean.to_excel('all_data.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nAS_6f9rbjNq",
        "outputId": "489d19c9-5e41-4fd4-eaf9-bfa06495c9c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ICLR data first ten rows are \n",
            "                name             id metadata.source  \\\n",
            "0    ICLR_2017_1.pdf    ICLR_2017_1             CRF   \n",
            "1   ICLR_2017_10.pdf   ICLR_2017_10             CRF   \n",
            "2  ICLR_2017_100.pdf  ICLR_2017_100             CRF   \n",
            "3  ICLR_2017_101.pdf  ICLR_2017_101             CRF   \n",
            "4  ICLR_2017_102.pdf  ICLR_2017_102             CRF   \n",
            "5  ICLR_2017_103.pdf  ICLR_2017_103             CRF   \n",
            "6  ICLR_2017_104.pdf  ICLR_2017_104             CRF   \n",
            "7  ICLR_2017_105.pdf  ICLR_2017_105             CRF   \n",
            "8  ICLR_2017_106.pdf  ICLR_2017_106             CRF   \n",
            "9  ICLR_2017_107.pdf  ICLR_2017_107             CRF   \n",
            "\n",
            "                                      metadata.title  \\\n",
            "0  MAKING NEURAL PROGRAMMING ARCHITECTURES GENERA...   \n",
            "1  Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT WITH ...   \n",
            "2  INTROSPECTION:ACCELERATING NEURAL NETWORK TRAI...   \n",
            "3        HYPERBAND: BANDIT-BASED CONFIGURATION EVAL-   \n",
            "4                  LIE-ACCESS NEURAL TURING MACHINES   \n",
            "5                    QUASI-RECURRENT NEURAL NETWORKS   \n",
            "6                   RECURRENT ENVIRONMENT SIMULATORS   \n",
            "7  EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES...   \n",
            "8  TRANSFER FROM MULTIPLE SOURCES IN THE SAME DOMAIN   \n",
            "9  MULTI-VIEW RECURRENT NEURAL ACOUSTIC WORD EMBE...   \n",
            "\n",
            "                                    metadata.authors  \\\n",
            "0            [Jonathon Cai, Richard Shin, Dawn Song]   \n",
            "1  [Shixiang Gu, Timothy Lillicrap, Zoubin Ghahra...   \n",
            "2             [Abhishek Sinha, Balaji Krishnamurthy]   \n",
            "3  [UATION FOR, HYPERPARAMETER OPTIMIZATION, Lish...   \n",
            "4                                        [Greg Yang]   \n",
            "5    [James Bradbury, Stephen Merity, Caiming Xiong]   \n",
            "6  [Silvia Chiappa, Sébastien Racaniere, Daan Wie...   \n",
            "7  [Aravind Rajeswaran, Sarvjeet Ghotra, Balarama...   \n",
            "8  [Janarthanan Rajendran, Aravind S. Lakshminara...   \n",
            "9                           [Wanjia He, Weiran Wang]   \n",
            "\n",
            "                                     metadata.emails  \\\n",
            "0  [jonathon@cs.berkeley.edu, ricshin@cs.berkeley...   \n",
            "1                                                 []   \n",
            "2                                                 []   \n",
            "3  [lishal@cs.ucla.edu,, ameet@cs.ucla.edu,, kjam...   \n",
            "4                                                 []   \n",
            "5  [james.bradbury@salesforce.com, smerity@salesf...   \n",
            "6                               [shakir}@google.com]   \n",
            "7  [aravraj@cs.washington.edu,, sarvjeet.13it236@...   \n",
            "8  [rjana@umich.edu, aravindsrinivas@gmail.com, m...   \n",
            "9  [wanjia@ttic.edu, weiranwang@ttic.edu, klivesc...   \n",
            "\n",
            "                                   metadata.sections  \\\n",
            "0  [{'heading': '1 INTRODUCTION', 'text': 'Traini...   \n",
            "1  [{'heading': '1 INTRODUCTION', 'text': 'Model-...   \n",
            "2  [{'heading': None, 'text': 'Neural Networks ar...   \n",
            "3  [{'heading': '1 INTRODUCTION', 'text': 'The ta...   \n",
            "4  [{'heading': '1 INTRODUCTION', 'text': 'Recent...   \n",
            "5  [{'heading': '1 INTRODUCTION', 'text': 'Recurr...   \n",
            "6  [{'heading': '1 INTRODUCTION', 'text': 'In ord...   \n",
            "7  [{'heading': '1 INTRODUCTION', 'text': 'Reinfo...   \n",
            "8  [{'heading': None, 'text': 'Transferring knowl...   \n",
            "9  [{'heading': '1 INTRODUCTION', 'text': 'Word e...   \n",
            "\n",
            "                                 metadata.references  \\\n",
            "0  [{'title': 'Learning efficient algorithms with...   \n",
            "1  [{'title': 'Input convex neural networks', 'au...   \n",
            "2  [{'title': 'Learning to learn by gradient desc...   \n",
            "3  [{'title': 'Oracle inequalities for computatio...   \n",
            "4  [{'title': 'Neural Turing Machines', 'author':...   \n",
            "5  [{'title': 'Neural machine translation by join...   \n",
            "6  [{'title': 'Finite-time analysis of the multia...   \n",
            "7  [{'title': 'Using inaccurate models in reinfor...   \n",
            "8  [{'title': 'Robot learning from demonstration'...   \n",
            "9  [{'title': 'Query by example search on speech ...   \n",
            "\n",
            "                          metadata.referenceMentions  metadata.year  ...  \\\n",
            "0  [{'referenceID': 4, 'context': 'Thus far, to e...         2017.0  ...   \n",
            "1  [{'referenceID': 16, 'context': 'It has recent...         2017.0  ...   \n",
            "2  [{'referenceID': 7, 'context': 'Some of them a...         2017.0  ...   \n",
            "3  [{'referenceID': 21, 'context': 'In an effort ...         2017.0  ...   \n",
            "4  [{'referenceID': 0, 'context': 'External neura...         2017.0  ...   \n",
            "5  [{'referenceID': 28, 'context': 'RNN applicati...         2017.0  ...   \n",
            "6  [{'referenceID': 7, 'context': 'The need for e...         2017.0  ...   \n",
            "7  [{'referenceID': 14, 'context': ', 2016), simu...         2017.0  ...   \n",
            "8  [{'referenceID': 15, 'context': 'This can take...         2017.0  ...   \n",
            "9  [{'referenceID': 9, 'context': 'Word embedding...         2017.0  ...   \n",
            "\n",
            "              metadata.creator conference         decision  \\\n",
            "0  LaTeX with hyperref package       ICLR    Accept (Oral)   \n",
            "1  LaTeX with hyperref package       ICLR    Accept (Oral)   \n",
            "2  LaTeX with hyperref package       ICLR  Accept (Poster)   \n",
            "3  LaTeX with hyperref package       ICLR  Accept (Poster)   \n",
            "4                          TeX       ICLR  Accept (Poster)   \n",
            "5  LaTeX with hyperref package       ICLR  Accept (Poster)   \n",
            "6  LaTeX with hyperref package       ICLR  Accept (Poster)   \n",
            "7  LaTeX with hyperref package       ICLR  Accept (Poster)   \n",
            "8  LaTeX with hyperref package       ICLR  Accept (Poster)   \n",
            "9  LaTeX with hyperref package       ICLR  Accept (Poster)   \n",
            "\n",
            "                                                 url hasContent hasReview  \\\n",
            "0  http://openreview.net/pdf/342543971002b3e5f08b...       true      true   \n",
            "1  http://openreview.net/pdf/c210ff1a4868a532ec87...       true      true   \n",
            "2  http://openreview.net/pdf/f5316305b0560db06352...       true      true   \n",
            "3  http://openreview.net/pdf/a9263ffc193997e5041e...       true      true   \n",
            "4  http://openreview.net/pdf/993280417e5049272dcb...       true      true   \n",
            "5  http://openreview.net/pdf/a69b67683af8de0cd62a...       true      true   \n",
            "6  http://openreview.net/pdf/dc16b626b1ac211f99b7...       true      true   \n",
            "7  http://openreview.net/pdf/96d9f09439812742c506...       true      true   \n",
            "8  http://openreview.net/pdf/5ab63afda67c68cd39a6...       true      true   \n",
            "9  http://openreview.net/pdf/834028d78a4c420011b4...       true      true   \n",
            "\n",
            "                                               title  \\\n",
            "0  Making Neural Programming Architectures Genera...   \n",
            "1  Q-Prop: Sample-Efficient Policy Gradient with ...   \n",
            "2  Introspection:Accelerating Neural Network Trai...   \n",
            "3  Hyperband: Bandit-Based Configuration Evaluati...   \n",
            "4                  Lie-Access Neural Turing Machines   \n",
            "5                    Quasi-Recurrent Neural Networks   \n",
            "6                   Recurrent Environment Simulators   \n",
            "7  EPOpt: Learning Robust Neural Network Policies...   \n",
            "8  Attend, Adapt and Transfer: Attentive Deep Arc...   \n",
            "9  Multi-view Recurrent Neural Acoustic Word Embe...   \n",
            "\n",
            "                                             authors  \\\n",
            "0            [Jonathon Cai, Richard Shin, Dawn Song]   \n",
            "1  [Shixiang Gu, Timothy Lillicrap, Zoubin Ghahra...   \n",
            "2  [Abhishek Sinha, Aahitagni Mukherjee, Mausoom ...   \n",
            "3  [Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afs...   \n",
            "4                        [Greg Yang, Alexander Rush]   \n",
            "5  [James Bradbury, Stephen Merity, Caiming Xiong...   \n",
            "6  [Silvia Chiappa, Sébastien Racaniere, Daan Wie...   \n",
            "7  [Aravind Rajeswaran, Sarvjeet Ghotra, Balarama...   \n",
            "8  [Janarthanan Rajendran, Aravind Lakshminarayan...   \n",
            "9            [Wanjia He, Weiran Wang, Karen Livescu]   \n",
            "\n",
            "                                             reviews metaReview  \n",
            "0  [{'review': 'This paper argues that being able...        NaN  \n",
            "1  [{'review': 'This paper proposed a new policy ...        NaN  \n",
            "2  [{'review': 'The paper reads well and the idea...        NaN  \n",
            "3  [{'review': 'This was an interesting paper. Th...        NaN  \n",
            "4  [{'review': 'The paper introduces a novel memo...        NaN  \n",
            "5  [{'review': 'The authors describe the use of c...        NaN  \n",
            "6  [{'review': '[UPDATE]\n",
            "After going through the ...        NaN  \n",
            "7  [{'review': 'This paper explores ensemble opti...        NaN  \n",
            "8  [{'review': 'In this paper a well known soft m...        NaN  \n",
            "9  [{'review': 'Pros:\n",
            "  Interesting training crit...        NaN  \n",
            "\n",
            "[10 rows x 21 columns]\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "NIPS data first ten rows are \n",
            "              name             id metadata.source  \\\n",
            "0  NIPS_2016_1.pdf    NIPS_2016_1             CRF   \n",
            "1              NaN   NIPS_2016_10             NaN   \n",
            "2              NaN  NIPS_2016_100             NaN   \n",
            "3              NaN  NIPS_2016_101             NaN   \n",
            "4              NaN  NIPS_2016_102             NaN   \n",
            "5              NaN  NIPS_2016_103             NaN   \n",
            "6              NaN  NIPS_2016_104             NaN   \n",
            "7              NaN  NIPS_2016_105             NaN   \n",
            "8              NaN  NIPS_2016_106             NaN   \n",
            "9              NaN  NIPS_2016_107             NaN   \n",
            "\n",
            "                                      metadata.title  \\\n",
            "0  Scan Order in Gibbs Sampling: Models in Which ...   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8                                                NaN   \n",
            "9                                                NaN   \n",
            "\n",
            "                                    metadata.authors  \\\n",
            "0  [Bryan He, Christopher De Sa, Ioannis Mitliagkas]   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8                                                NaN   \n",
            "9                                                NaN   \n",
            "\n",
            "                                     metadata.emails  \\\n",
            "0  [bryanhe@stanford.edu, cdesa@stanford.edu, imi...   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8                                                NaN   \n",
            "9                                                NaN   \n",
            "\n",
            "                                   metadata.sections  \\\n",
            "0  [{'heading': '1 Introduction', 'text': 'Gibbs ...   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8                                                NaN   \n",
            "9                                                NaN   \n",
            "\n",
            "                                 metadata.references  \\\n",
            "0  [{'title': 'Mixing times of the biased card sh...   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8                                                NaN   \n",
            "9                                                NaN   \n",
            "\n",
            "                          metadata.referenceMentions  metadata.year  ...  \\\n",
            "0  [{'referenceID': 7, 'context': 'A major use of...         2016.0  ...   \n",
            "1                                                NaN            NaN  ...   \n",
            "2                                                NaN            NaN  ...   \n",
            "3                                                NaN            NaN  ...   \n",
            "4                                                NaN            NaN  ...   \n",
            "5                                                NaN            NaN  ...   \n",
            "6                                                NaN            NaN  ...   \n",
            "7                                                NaN            NaN  ...   \n",
            "8                                                NaN            NaN  ...   \n",
            "9                                                NaN            NaN  ...   \n",
            "\n",
            "             metadata.creator conference decision  \\\n",
            "0  pdftk 2.02 - www.pdftk.com       NIPS   Accept   \n",
            "1                         NaN       NIPS   Accept   \n",
            "2                         NaN       NIPS   Accept   \n",
            "3                         NaN       NIPS   Accept   \n",
            "4                         NaN       NIPS   Accept   \n",
            "5                         NaN       NIPS   Accept   \n",
            "6                         NaN       NIPS   Accept   \n",
            "7                         NaN       NIPS   Accept   \n",
            "8                         NaN       NIPS   Accept   \n",
            "9                         NaN       NIPS   Accept   \n",
            "\n",
            "                                                 url hasContent hasReview  \\\n",
            "0  http://papers.nips.cc/paper/6589-scan-order-in...       true      true   \n",
            "1  http://papers.nips.cc/paper/6096-learning-a-pr...       true      true   \n",
            "2  http://papers.nips.cc/paper/6146-soundnet-lear...       true      true   \n",
            "3  http://papers.nips.cc/paper/6114-weight-normal...       true      true   \n",
            "4  http://papers.nips.cc/paper/6207-efficient-sec...       true      true   \n",
            "5  http://papers.nips.cc/paper/6583-dynamic-mode-...       true      true   \n",
            "6  http://papers.nips.cc/paper/6585-distributed-f...       true      true   \n",
            "7  http://papers.nips.cc/paper/6056-the-robustnes...       true      true   \n",
            "8  http://papers.nips.cc/paper/6558-efficient-and...       true      true   \n",
            "9  http://papers.nips.cc/paper/6463-perforatedcnn...       true      true   \n",
            "\n",
            "                                               title  \\\n",
            "0  Scan Order in Gibbs Sampling: Models in Which ...   \n",
            "1  Learning a Probabilistic Latent Space of Objec...   \n",
            "2  SoundNet: Learning Sound Representations from ...   \n",
            "3  Weight Normalization: A Simple Reparameterizat...   \n",
            "4  Efficient Second Order Online Learning by Sket...   \n",
            "5  Dynamic Mode Decomposition with Reproducing Ke...   \n",
            "6  Distributed Flexible Nonlinear Tensor Factoriz...   \n",
            "7            The Robustness of Estimator Composition   \n",
            "8  Efficient and Robust Spiking Neural Circuit fo...   \n",
            "9  PerforatedCNNs: Acceleration through Eliminati...   \n",
            "\n",
            "                                             authors  \\\n",
            "0  [Bryan D. He, Christopher M. De Sa, Ioannis Mi...   \n",
            "1  [Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill ...   \n",
            "2     [Yusuf Aytar, Carl Vondrick, Antonio Torralba]   \n",
            "3                     [Tim Salimans, Durk P. Kingma]   \n",
            "4  [Haipeng Luo, Alekh Agarwal, Nicolò Cesa-Bianc...   \n",
            "5                               [Yoshinobu Kawahara]   \n",
            "6  [Shandian Zhe, Kai Zhang, Pengyuan Wang, Kuang...   \n",
            "7                   [Pingfan Tang, Jeff M. Phillips]   \n",
            "8  [Pulkit Tandon, Yash H. Malviya, Bipin Rajendran]   \n",
            "9  [Mikhail Figurnov, Aizhan Ibraimova, Dmitry P....   \n",
            "\n",
            "                                             reviews metaReview  \n",
            "0  [{'review': 'This paper is interested in compa...        NaN  \n",
            "1  [{'review': 'The paper applies both generative...        NaN  \n",
            "2  [{'review': 'This paper describes a method to ...        NaN  \n",
            "3  [{'review': 'Inspired by batch-normalisation, ...        NaN  \n",
            "4  [{'review': 'The authors strive to make second...        NaN  \n",
            "5  [{'review': 'This paper introduced a spectral ...        NaN  \n",
            "6  [{'review': 'The paper proposes a non-linear t...        NaN  \n",
            "7  [{'review': 'The authors study the effect of c...        NaN  \n",
            "8  [{'review': 'The paper descries a navigation s...        NaN  \n",
            "9  [{'review': 'The paper tries to speed-up CNN i...        NaN  \n",
            "\n",
            "[10 rows x 21 columns]\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'name', there are 8856 unique values which are given by\n",
            "['ICLR_2017_1.pdf' 'ICLR_2017_10.pdf' 'ICLR_2017_100.pdf' ...\n",
            " 'NIPS_2019_NIPS_2019_NIPS_2019_NIPS_2019_558.pdf'\n",
            " 'NIPS_2019_NIPS_2019_NIPS_2019_NIPS_2019_564.pdf'\n",
            " 'NIPS_2019_NIPS_2019_NIPS_2019_NIPS_2019_570.pdf']\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'id', there are 9128 unique values which are given by\n",
            "['ICLR_2017_1' 'ICLR_2017_10' 'ICLR_2017_100' ...\n",
            " 'NIPS_2019_NIPS_2019_NIPS_2019_NIPS_2019_558'\n",
            " 'NIPS_2019_NIPS_2019_NIPS_2019_NIPS_2019_564'\n",
            " 'NIPS_2019_NIPS_2019_NIPS_2019_NIPS_2019_570']\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.source', there are 3 unique values which are given by\n",
            "['CRF' nan 'META']\n",
            " \n",
            " and histogram of this column is given by \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.title', there are 5459 unique values which are given by\n",
            "['MAKING NEURAL PROGRAMMING ARCHITECTURES GENERALIZE VIA RECURSION'\n",
            " 'Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT WITH AN OFF-POLICY CRITIC'\n",
            " 'INTROSPECTION:ACCELERATING NEURAL NETWORK TRAINING BY LEARNING WEIGHT EVOLUTION'\n",
            " ... 'Distributional Reward Decomposition for Reinforcement Learning'\n",
            " 'Learning to Perform Local Rewriting for Combinatorial Optimization'\n",
            " 'Bayesian Learning of Sum-Product Networks']\n",
            " \n",
            " and the following unique values occur more than once\n",
            "metadata.title\n",
            "RECURRENT NEURAL NETWORKS                                                           5\n",
            "DEEP REINFORCEMENT LEARNING                                                         3\n",
            "CONVOLUTIONAL NEURAL NETWORKS                                                       3\n",
            "DEEP NEURAL NETWORKS                                                                3\n",
            "Launch and Iterate: Reducing Prediction Churn                                       2\n",
            "MASSIVELY PARALLEL HYPERPARAMETER TUNING                                            2\n",
            "CONTROLLABLE SPEECH SYNTHESIS                                                       2\n",
            "GRAPH NEURAL NETWORKS                                                               2\n",
            "DIVERSE, UNCERTAIN GRADIENT LOWER BOUNDS                                            2\n",
            "PUSHING THE BOUNDS OF DROPOUT                                                       2\n",
            "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning    2\n",
            "DOUBLE NEURAL COUNTERFACTUAL REGRET MINIMIZATION                                    2\n",
            "GENERATIVE ADVERSARIAL NETWORKS                                                     2\n",
            "Name: count, dtype: int64\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.authors', data are given in the list format\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.emails', data are given in the list format\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.sections', data are given in the list format\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.references', data are given in the list format\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.referenceMentions', data are given in the list format\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.year', there are 8 unique values which are given by\n",
            "[2017. 2018. 2016.   nan 2019. 1969.    0. 2020.]\n",
            " \n",
            " and histogram of this column is given by \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.abstractText', there are 8844 unique values which are given by\n",
            "['Empirically, neural networks that attempt to learn programs from data have exhibited poor generalizability. Moreover, it has traditionally been difficult to reason about the behavior of these models beyond a certain level of input complexity. In order to address these issues, we propose augmenting neural architectures with a key abstraction: recursion. As an application, we implement recursion in the Neural Programmer-Interpreter framework on four tasks: grade-school addition, bubble sort, topological sort, and quicksort. We demonstrate superior generalizability and interpretability with small amounts of training data. Recursion divides the problem into smaller pieces and drastically reduces the domain of each neural network component, making it tractable to prove guarantees about the overall system’s behavior. Our experience suggests that in order for neural architectures to robustly learn program semantics, it is necessary to incorporate a concept like recursion.'\n",
            " 'Model-free deep reinforcement learning (RL) methods have been successful in a wide variety of simulated domains. However, a major obstacle facing deep RL in the real world is their high sample complexity. Batch policy gradient methods offer stable learning, but at the cost of high variance, which often requires large batches. TD-style methods, such as off-policy actor-critic and Q-learning, are more sample-efficient but biased, and often require costly hyperparameter sweeps to stabilize. In this work, we aim to develop methods that combine the stability of policy gradients with the efficiency of off-policy RL. We present Q-Prop, a policy gradient method that uses a Taylor expansion of the off-policy critic as a control variate. Q-Prop is both sample efficient and stable, and effectively combines the benefits of on-policy and off-policy methods. We analyze the connection between Q-Prop and existing model-free algorithms, and use control variate theory to derive two variants of Q-Prop with conservative and aggressive adaptation. We show that conservative Q-Prop provides substantial gains in sample efficiency over trust region policy optimization (TRPO) with generalized advantage estimation (GAE), and improves stability over deep deterministic policy gradient (DDPG), the stateof-the-art on-policy and off-policy methods, on OpenAI Gym’s MuJoCo continuous control environments.'\n",
            " 'Neural Networks are function approximators that have achieved state-of-the-art accuracy in numerous machine learning tasks. In spite of their great success in terms of accuracy, their large training time makes it difficult to use them for various tasks. In this paper, we explore the idea of learning weight evolution pattern from a simple network for accelerating training of novel neural networks. We use a neural network to learn the training pattern from MNIST classification and utilize it to accelerate training of neural networks used for CIFAR-10 and ImageNet classification. Our method has a low memory footprint and is computationally efficient. This method can also be used with other optimizers to give faster convergence. The results indicate a general trend in the weight evolution during training of neural networks.'\n",
            " ...\n",
            " 'Many reinforcement learning (RL) tasks have specific properties that can be leveraged to modify existing RL algorithms to adapt to those tasks and further improve performance, and a general class of such properties is the multiple reward channel. In those environments the full reward can be decomposed into sub-rewards obtained from different channels. Existing work on reward decomposition either requires prior knowledge of the environment to decompose the full reward, or decomposes reward without prior knowledge but with degraded performance. In this paper, we propose Distributional Reward Decomposition for Reinforcement Learning (DRDRL), a novel reward decomposition algorithm which captures the multiple reward channel structure under distributional setting. Empirically, our method captures the multi-channel structure and discovers meaningful reward decomposition, without any requirements on prior knowledge. Consequently, our agent achieves better performance than existing methods on environments with multiple reward channels.'\n",
            " 'Search-based methods for hard combinatorial optimization are often guided by heuristics. Tuning heuristics in various conditions and situations is often timeconsuming. In this paper, we propose NeuRewriter that learns a policy to pick heuristics and rewrite the local components of the current solution to iteratively improve it until convergence. The policy factorizes into a region-picking and a rule-picking component, each parameterized by a neural network trained with actor-critic methods in reinforcement learning. NeuRewriter captures the general structure of combinatorial problems and shows strong performance in three versatile tasks: expression simplification, online job scheduling and vehicle routing problems. NeuRewriter outperforms the expression simplification component in Z3 [15]; outperforms DeepRM [33] and Google OR-tools [19] in online job scheduling; and outperforms recent neural baselines [35, 29] and Google OR-tools [19] in vehicle routing problems. 2'\n",
            " 'Sum-product networks (SPNs) are flexible density estimators and have received significant attention due to their attractive inference properties. While parameter learning in SPNs is well developed, structure learning leaves something to be desired: Even though there is a plethora of SPN structure learners, most of them are somewhat ad-hoc and based on intuition rather than a clear learning principle. In this paper, we introduce a well-principled Bayesian framework for SPN structure learning. First, we decompose the problem into i) laying out a computational graph, and ii) learning the so-called scope function over the graph. The first is rather unproblematic and akin to neural network architecture validation. The second represents the effective structure of the SPN and needs to respect the usual structural constraints in SPN, i.e. completeness and decomposability. While representing and learning the scope function is somewhat involved in general, in this paper, we propose a natural parametrisation for an important and widely used special case of SPNs. These structural parameters are incorporated into a Bayesian model, such that simultaneous structure and parameter learning is cast into monolithic Bayesian posterior inference. In various experiments, our Bayesian SPNs often improve test likelihoods over greedy SPN learners. Further, since the Bayesian framework protects against overfitting, we can evaluate hyper-parameters directly on the Bayesian model score, waiving the need for a separate validation set, which is especially beneficial in low data regimes. Bayesian SPNs can be applied to heterogeneous domains and can easily be extended to nonparametric formulations. Moreover, our Bayesian approach is the first, which consistently and robustly learns SPN structures under missing data.']\n",
            " \n",
            " and the following unique values occur more than once\n",
            "metadata.abstractText\n",
            "The application of stochastic variance reduction to optimization has shown remarkable recent theoretical and practical success. The applicability of these techniques to the hard non-convex optimization problems encountered during training of modern deep neural networks is an open problem. We show that naive application of the SVRG technique and related approaches fail, and explore why.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2\n",
            "We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2\n",
            "Practical applications of machine learning often involve successive training iterations with changes to features and training examples. Ideally, changes in the output of any new model should only be improvements (wins) over the previous iteration, but in practice the predictions may change neutrally for many examples, resulting in extra net-zero wins and losses, referred to as unnecessary churn. These changes in the predictions are problematic for usability for some applications, and make it harder and more expensive to measure if a change is statistically significant positive. In this paper, we formulate the problem and present a stabilization operator to regularize a classifier towards a previous classifier. We use a Markov chain Monte Carlo stabilization operator to produce a model with more consistent predictions without adversely affecting accuracy. We investigate the properties of the proposal with theoretical analysis. Experiments on benchmark datasets for different classification algorithms demonstrate the method and the resulting reduction in churn. 1 The Curse of Version 2.0 In most practical settings, training and launching an initial machine-learned model is only the first step: as new and improved features are created, additional training data is gathered, and the model and learning algorithm are improved, it is natural to launch a series of ever-improving models. Each new candidate may bring wins, but also unnecessary changes. In practice, it is desirable to minimize any unnecessary changes for two key reasons. First, unnecessary changes can hinder usability and debugability as they can be disorienting to users and follow-on system components. Second, unnecessary changes make it more difficult to measure with statistical confidence whether the change is truly an improvement. For both these reasons, there is great interest in making only those changes that are wins, and minimizing any unnecessary changes, while making sure such process does not hinder the overall accuracy objective. There is already a large body of work in machine learning that treats the stability of learning algorithms. These range from the early works of Devroye and Wagner [1] and Vapnik [2, 3] to more recent studies of learning stability in more general hypothesis spaces [4, 5, 6]. Most of the literature on this topic focus on stability of the learning algorithm in terms of the risk or loss function and how such properties translate into uniform generalization with specific convergence rates. We build on these notions, but the problem treated here is substantively different. We address the problem of training consecutive classifiers to reduce unnecessary changes in the presence of realistic evolution of the problem domain and the training sets over time. The main contributions of this paper include: (I) discussion and formulation of the “churn” metric between trained models, (II) design of stabilization operators for regularization towards a previous model, (III) proposing a Markov chain Monte Carlo (MCMC) stabilization technique, (VI) theoretical analysis of the proposed stabilization in terms of churn, and (V) empirical analysis of the proposed methods on benchmark datasets with different classification algorithms. 30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. Table 1: Win-loss ratio (WLR) needed to establish a change is statistically significant at the p = 0.05 level for k wins out of n diffs from a binomial distribution. The empirical WLR column shows the WLR one must actually see in the diffs. The true WLR column is the WLR the change must have so that any random draw of diffs has at least a 95% chance of producing the needed empirical WLR. # Diffs Min # Wins Max # Losses Empirical WLR True WLR Needed Allowed Needed Needed 10 9 1 9.000 26.195 100 59 41 1.439 1.972 1,000 527 473 1.114 1.234 10,000 5,083 4,917 1.034 1.068 1.1 Testing for Improvements In the machine learning literature, it is common to compare classifiers on a fixed pre-labeled test set. However, a fixed test set has a few practical downsides. First, if many potential changes to the model are evaluated on the same dataset, it becomes difficult to avoid observing spurious positive effects that are actually due to chance. Second, the true test distribution may be evolving over time, meaning that a fixed test set will eventually diverge from the true distribution of interest. Third, and most important to our discussion, any particular change may affect only a small subset of the test examples, leaving too small a sample of differences (diffs) to determine whether a change is statistically significant. For example, suppose one has a fixed test set of 10,000 samples with which to evaluate a classifier. Consider a change to one of the features, say a Boolean string-similarity feature that causes the feature to match more synonyms, and suppose that re-training a classifier with this small change to this one feature impacts only 0.1% of random examples. Then only 10 of the 10,000 test examples would be affected. As shown in the first row of Table 1, given only 10 diffs, there must be 9 or more wins to declare the change statistically significantly positive for p = 0.05. Note that cross-validation (CV), even in leave-one-out form, does not solve this issue. First, we are still bound by the size of the training set which might not include enough diffs between the two models. Second, and more importantly, the model in the previous iteration has likely seen the entire dataset, which breaks the independence assumption needed for the statistical test. To address these problems and ensure a fresh, sufficiently large test set for each comparison, practitioners often instead measure changes on a set of diffs for the proposed change. For example, to compare classifier A and B, each classifier is evaluated on a billion unlabeled examples, and then the set of diffs is defined as those examples for which classifiers A and B predict a different class.    2\n",
            "There are time series that are amenable to recurrent neural network (RNN) solutions when treated as sequences, but some series, e.g. asynchronous time series, provide a richer variation of feature types than current RNN cells take into account. In order to address such situations, we introduce a unified RNN that handles five different feature types, each in a different manner. Our RNN framework separates sequential features into two groups dependent on their frequency, which we call sparse and dense features, and which affect cell updates differently. Further, we also incorporate time features at the sequential level that relate to the time between specified events in the sequence and are used to modify the cell’s memory state. We also include two types of static (whole sequence level) features, one related to time and one not, which are combined with the encoder output. The experiments show that the proposed modeling framework does increase performance compared to standard cells.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2\n",
            "While variational dropout approaches have been shown to be effective for network sparsification, they are still suboptimal in the sense that they set the dropout rate for each neuron without consideration of the input data. With such input-independent dropout, each neuron is evolved to be generic across inputs, which makes it difficult to sparsify networks without accuracy loss. To overcome this limitation, we propose adaptive variational dropout whose probabilities are drawn from sparsity-inducing beta-Bernoulli prior. It allows each neuron to be evolved either to be generic or specific for certain inputs, or dropped altogether. Such input-adaptive sparsityinducing dropout allows the resulting network to tolerate larger degree of sparsity without losing its expressive power by removing redundancies among features. We validate our dependent variational beta-Bernoulli dropout on multiple public datasets, on which it obtains significantly more compact networks than baseline methods, with consistent accuracy improvements over the base networks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2\n",
            "Name: count, dtype: int64\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metadata.creator', there are 59 unique values which are given by\n",
            "['LaTeX with hyperref package' 'TeX' nan ' TeX output 2016.11.06:0051'\n",
            " ' TeX output 2016.11.25:2110' 'gnuplot 4.6 patchlevel 6'\n",
            " 'Microsoft® Word 2010' ' TeX output 2016.10.29:0255' 'David M. Jones'\n",
            " 'LaTeX with hyperref' 'Roman Novak' '预览' ' TeX output 2018.01.09:1236'\n",
            " ' TeX output 2017.12.25:2116' '預覽程式' 'pdftk 2.02 - www.pdftk.com'\n",
            " 'Preview' ' TeX output 2017.10.27:2255' ' TeX output 2017.10.28:0224'\n",
            " ' TeX output 2018.02.23:1429' ' TeX output 2018.09.28:0657'\n",
            " 'Microsoft® Word for Office 365' 'TexpadTeX CGPDFContext backend: 404'\n",
            " None 'TeXShop' 'TexpadTeX CGPDFContext backend: 420'\n",
            " 'cairo 1.14.6 (http://cairographics.org)' ' TeX output 2019.03.04:2042'\n",
            " ' TeX output 2018.11.27:1746' 'pdfLaTeX' ' TeX output 2018.11.14:1651'\n",
            " ' TeX output 2019.09.25:2108' ' TeX output 2019.11.15:1108'\n",
            " 'PDFsam Basic v4.0.3' 'TexpadTeX CGPDFContext backend: 474'\n",
            " 'TexpadTeX CGPDFContext backend: 447' 'Acrobat PDFMaker 17 for Word'\n",
            " ' TeX output 2019.11.15:1610' ' TeX output 2019.11.13:1918'\n",
            " ' TeX output 2019.11.15:1924' 'Microsoft® Word 2016'\n",
            " ' TeX output 2019.11.16:0731' ' TeX output 2019.09.25:2359' 'Creator'\n",
            " ' TeX output 2019.12.23:2133' ' TeX output 2020.02.14:2215'\n",
            " 'TexpadTeX CGPDFContext backend: 493' 'PScript5.dll Version 5.2.2' ''\n",
            " 'Acrobat PDFMaker 10.1 Word 版' 'pdftk 2.01 - www.pdftk.com'\n",
            " 'pdfsam-console (Ver. 2.4.3e)' 'Edited with pdfresizer.com'\n",
            " 'pdfsam-console (Ver. 2.4.1e)' 'pdftk 3.0.0 - www.pdftk.com' 'PDFium'\n",
            " 'PDFsam Basic v4.0.5' 'pdftk-java 3.0.6' 'pdftk 3.0.2 - www.pdftk.com']\n",
            " \n",
            " and the following unique values occur more than once\n",
            "metadata.creator\n",
            "LaTeX with hyperref package            4594\n",
            "LaTeX with hyperref                     528\n",
            "TeX                                     157\n",
            "pdftk 2.02 - www.pdftk.com              132\n",
            "pdftk 2.01 - www.pdftk.com               20\n",
            "Preview                                   8\n",
            "pdftk 3.0.0 - www.pdftk.com               6\n",
            "pdftk 3.0.2 - www.pdftk.com               5\n",
            "TeXShop                                   4\n",
            "pdftk-java 3.0.6                          4\n",
            "TexpadTeX CGPDFContext backend: 474       3\n",
            "pdfLaTeX                                  2\n",
            "Microsoft® Word 2016                      2\n",
            "TexpadTeX CGPDFContext backend: 420       2\n",
            "TexpadTeX CGPDFContext backend: 493       2\n",
            "                                          2\n",
            "PDFium                                    2\n",
            "TexpadTeX CGPDFContext backend: 447       2\n",
            "Roman Novak                               2\n",
            "Microsoft® Word 2010                      2\n",
            "David M. Jones                            2\n",
            "Edited with pdfresizer.com                2\n",
            "Name: count, dtype: int64\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'conference', there are 3 unique values which are given by\n",
            "['ICLR' nan 'NIPS']\n",
            " \n",
            " and histogram of this column is given by \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'decision', there are 8 unique values which are given by\n",
            "['Accept (Oral)' 'Accept (Poster)' 'Invite to Workshop Track' 'Reject' nan\n",
            " 'Accept (Spotlight)' 'Accept (Talk)' 'Accept']\n",
            " \n",
            " and histogram of this column is given by \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'url', there are 8878 unique values which are given by\n",
            "['http://openreview.net/pdf/342543971002b3e5f08be11d9a6da60b594a6b47.pdf'\n",
            " 'http://openreview.net/pdf/c210ff1a4868a532ec87ee0da3c6e4254ee567fb.pdf'\n",
            " 'http://openreview.net/pdf/f5316305b0560db063525a71f36ca95d1932981e.pdf'\n",
            " ...\n",
            " 'http://papers.nips.cc/paper/9291-region-mutual-information-loss-for-semantic-segmentation.pdf'\n",
            " 'http://papers.nips.cc/paper/9292-learning-stable-deep-dynamics-models.pdf'\n",
            " 'http://papers.nips.cc/paper/9293-image-captioning-transforming-objects-into-words.pdf']\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'hasContent', there are 3 unique values which are given by\n",
            "['true' 'false' nan]\n",
            " \n",
            " and histogram of this column is given by \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'hasReview', there are 3 unique values which are given by\n",
            "['true' nan 'false']\n",
            " \n",
            " and histogram of this column is given by \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'title', there are 8826 unique values which are given by\n",
            "['Making Neural Programming Architectures Generalize via Recursion'\n",
            " 'Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic'\n",
            " 'Introspection:Accelerating Neural Network Training By Learning Weight Evolution'\n",
            " ... 'Region Mutual Information Loss for Semantic Segmentation'\n",
            " 'Learning Stable Deep Dynamics Models'\n",
            " 'Image Captioning: Transforming Objects into Words']\n",
            " \n",
            " and the following unique values occur more than once\n",
            "title\n",
            "NA                                                                                  6\n",
            "N/A                                                                                 3\n",
            "Visualizing the Loss Landscape of Neural Nets                                       2\n",
            "Prototypical Networks for Few-shot Learning                                         2\n",
            "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning    2\n",
            "Double Neural Counterfactual Regret Minimization                                    2\n",
            "Heterogeneous Bitwidth Binarization in Convolutional Neural Networks                2\n",
            "Unified recurrent network for many feature types                                    2\n",
            "Data augmentation instead of explicit regularization                                2\n",
            "Deep Imitative Models for Flexible Inference, Planning, and Control                 2\n",
            "Graph2Seq: Scalable Learning Dynamics for Graphs                                    2\n",
            "Open Loop Hyperparameter Optimization and Determinantal Point Processes             2\n",
            "Loss Functions for Multiset Prediction                                              2\n",
            "Backprop with Approximate Activations for Memory-efficient Network Training         2\n",
            "Dimension-Free Bounds for Low-Precision Training                                    2\n",
            "Value Propagation Networks                                                          2\n",
            "Incremental Few-Shot Learning with Attention Attractor Networks                     2\n",
            "Massively Parallel Hyperparameter Tuning                                            2\n",
            "Quadrature-based features for kernel approximation                                  2\n",
            "Unsupervised Meta-Learning for Reinforcement Learning                               2\n",
            "Weakly-supervised Knowledge Graph Alignment with Adversarial Learning               2\n",
            "Self-Supervised Generalisation with Meta Auxiliary Learning                         2\n",
            "On the Ineffectiveness of Variance Reduced Optimization for Deep Learning           2\n",
            "DppNet: Approximating Determinantal Point Processes with Deep Networks              2\n",
            "Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger      2\n",
            "Pushing the bounds of dropout                                                       2\n",
            "Learning to Infer Graphics Programs from Hand-Drawn Images                          2\n",
            "Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update           2\n",
            "Tree-to-tree Neural Networks for Program Translation                                2\n",
            "Name: count, dtype: int64\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'authors', data are given in the list format\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'reviews', data are given in the list format\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "For the column 'metaReview', there are 5876 unique values which are given by\n",
            "[nan\n",
            " 'This paper analyzes a problem with the convergence of Adam, and presents a solution. It identifies an error in the convergence proof of Adam (which also applies to related methods such as RMSProp) and gives a simple example where it fails to converge. The paper then repairs the algorithm in a way that guarantees convergence without introducing much computational or memory overhead. There ought to be a lot of interest in this paper: Adam is a widely used algorithm, but sometimes underperforms SGD on certain problems, and this could be part of the explanation. The fix is both principled and practical. Overall, this is a strong paper, and I recommend acceptance.\\n'\n",
            " 'The reviewers are unanimous in finding the work in this paper highly novel and significant.  They have provided detailed discussions to back up this assessment.  The reviewer comments surprisingly included a critique that  \"the scientific content of the work has critical conceptual flaws\" (!)  However, the author rebuttal persuaded the reviewers that the concerns were largely addressed.'\n",
            " ...\n",
            " 'The reviews were leaning positive, and after the rebuttal, two of the reviewers recommended to accept, while R3 remained at the \"marginally below\" score. I agree that most of the reviewers comments were addressed in the rebuttal, and concur with the majority vote here. The paper is an incremental, but worthy addition to the evolving semantic segmentation craft. I strongly encourage the authors to incorporate the responses in the rebuttal into the final version, and in particular, to make sure to include some qualitative results. '\n",
            " \"The paper has a very strong theoretical contribution which all reviewers appreciated. The opinion about whether the experimental evaluation is sufficient was rather divided. I'll follow the opinion of the majority of the reviewers that in-depth empirical evaluations can (and should) be done in a follow-up paper.\"\n",
            " 'An object relation module is included into the transformer model. Improvements are demonstrated using this approach.  After reading the rebuttal the reviewers agreed that this is an interesting direction to pursue. The reviewers liked the method and partly the results presented in the rebuttal. However the reviewers also remained concerned that additional evidence is necessary (e.g., proper evaluation on test server, experimentation with different spatial features, more in-depth discussion of the attention visualizations, empirical comparison to prior work and human evaluation).  AC concurs and recommends acceptance as a poster.']\n",
            " \n",
            " and the following unique values occur more than once\n",
            "metaReview\n",
            "All reviewers agree to reject. While there were many positive points to this work, reviewers believed that it was not yet ready for acceptance.                                                                                         7\n",
            "All three reviewers are consistently negative on this paper. Thus a reject is recommended.                                                                                                                                              6\n",
            "The paper is rejected based on unanimous reviews.                                                                                                                                                                                       5\n",
            "This paper does not meet the acceptance bar this year, and thus I must recommend it for rejection.                                                                                                                                      5\n",
            "Reviewers are in a consensus and recommended to accept after engaging with the authors. Please take reviewers' comments into consideration to improve your submission for the camera ready.\\n                                           5\n",
            "This paper constitutes interesting progress on an important topic; the reviewers identify certain improvements and directions for future work, and I urge the authors to continue to develop refinements and extensions.                3\n",
            "The reviewers agree that this submission represents an important contribution to the field.  Please be sure to carefully review and address the concerns of all reviewers in the revision.                                              3\n",
            "Reviewers are in a consensus and recommended to reject after engaging with the authors. Please take reviewers' comments into consideration to improve your submission should you decide to resubmit.\\n                                  3\n",
            "The reviewers reached a consensus that the paper is not ready for publication in ICLR. (see more details in the reviews below. )                                                                                                        3\n",
            "The paper is proposed a rejection based on majority reviews.                                                                                                                                                                            3\n",
            "Three reviewers have assessed this paper and they have scored it 6/6/6 after rebuttal. Nonetheless, the reviewers have raised a number of criticisms and the authors are encouraged to resolve them for the camera-ready submission.    2\n",
            "This paper has been withdrawn by the authors.                                                                                                                                                                                           2\n",
            "The reviewers unanimously liked and recommended to accept the paper. The author feedback clarified some concerns that the reviewers had initially held.                                                                                 2\n",
            "The overall view of the reviewers is that the paper is not quite good enough as it stands. The reviewers also appreciate the contributions so taking the comments into account and resubmit elsewhere is encouraged.                    2\n",
            "The reviewers have reached consensus that while the paper is interesting, it could use more time.  We urge the authors to continue their investigations.                                                                                2\n",
            "The reviewers have agreed this work is not ready for publication at ICLR.                                                                                                                                                               2\n",
            "All reviewers agree in their assessment that this paper is not ready for acceptance into ICLR and the authors did not respond during the rebuttal phase.                                                                                2\n",
            "The reviewers unanimously recommend accept.                                                                                                                                                                                             2\n",
            "The reviewers agree the paper is not ready for publication.                                                                                                                                                                             2\n",
            "All the reviewers recommend rejecting the submission. There is no basis for acceptance.                                                                                                                                                 2\n",
            "All the reviewers agree that the paper presents an interesting result and is nicely written. Please incorporate reviewers' feedback. Congratulations on a nice result.                                                                  2\n",
            "All reviewers were positive about the contributions in the paper so I recommend acceptance. Congratulations! Please take into account all the reviewers' comments when preparing the final version of the paper.                        2\n",
            "All reviewers recommended accept.                                                                                                                                                                                                       2\n",
            "The reviewers agree this paper is not good enough for ICLR.                                                                                                                                                                             2\n",
            "The overall view of the reviewers is that the paper is not quite good enough as it stands. The reviewers also appreciates the contributions so taking the comments into account and resubmit elsewhere is encouraged.                   2\n",
            "All reviewers unanimously accept the paper.                                                                                                                                                                                             2\n",
            "Name: count, dtype: int64\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b2b5655fe57b>:70: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  NIPS_data_serialized = NIPS_data.applymap(lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x)\n",
            "<ipython-input-3-b2b5655fe57b>:84: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  data_clean = data_serialized.applymap(remove_illegal_chars)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary Results"
      ],
      "metadata": {
        "id": "nTFui3MQISoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing remaining libraries"
      ],
      "metadata": {
        "id": "NwWV_P1zUkZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import random\n",
        "import string\n",
        "# Neural Network Architecture and Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Training\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "# Performance Metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "# Natural Language Toolkit\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "# WANDB\n",
        "!pip install wandb\n",
        "import wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn_0U9ODWykO",
        "outputId": "4992ab62-8d78-463f-e567-4df69fc9b568"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting seed"
      ],
      "metadata": {
        "id": "NzUIO21LrOI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 34\n",
        "print(\"seed = \" + str(seed))\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(seed)\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed()\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "# incase pandas function involving randomness are used, then this seed value will be used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M8itCL4rLZY",
        "outputId": "9e9b7ecc-a0a7-4b6f-833e-b0799994d8c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed = 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop Words and Punctuation"
      ],
      "metadata": {
        "id": "Fsv7MP94gB63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "punct_table = str.maketrans('', '', string.punctuation)"
      ],
      "metadata": {
        "id": "sReVdc3WgsX7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing nan from Decision Parameters"
      ],
      "metadata": {
        "id": "OCYcHHzCh8BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean = data_clean[pd.notna(data_clean['decision'])]\n",
        "\n",
        "unique_labels = data_clean['decision'].unique()\n",
        "\n",
        "output_len = len(unique_labels)"
      ],
      "metadata": {
        "id": "8oPGFu_DlZRM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset class where texts are composed of titles and meta reviews and stop words, punctuation, nan, None, NA and N/A values are ignored"
      ],
      "metadata": {
        "id": "mXQRMWbbmDPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Most_Common_Count = 20000\n",
        "class ArticleDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = df.apply(\n",
        "            lambda row: \" \".join(\n",
        "                word.lower()\n",
        "                for val in [row.get('title'), row.get('metaReview')]\n",
        "                if pd.notna(val) and str(val).strip().upper() not in {\"NA\", \"N/A\"}\n",
        "                for word in word_tokenize(str(val).translate(punct_table))\n",
        "                if word.lower() not in stop_words\n",
        "            ),\n",
        "            axis=1\n",
        "        ).tolist()\n",
        "        self.max_len = max(len(text) for text in self.texts)\n",
        "        print(\"self.max_len: \" + str(self.max_len))\n",
        "        self.labels = df['decision'].tolist()\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
        "        self.vocab = self.build_vocab(self.texts)\n",
        "\n",
        "    def build_vocab(self, texts):\n",
        "        words = [word for text in texts for word in self.tokenizer(text.lower())]\n",
        "        most_common = Counter(words).most_common(Most_Common_Count)\n",
        "        vocab = {word: idx+2 for idx, (word, _) in enumerate(most_common)}  # 0=PAD, 1=UNK\n",
        "        vocab['<PAD>'] = 0\n",
        "        vocab['<UNK>'] = 1\n",
        "        return vocab\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        tokens = self.tokenizer(text.lower())\n",
        "        return [self.vocab.get(token, 1) for token in tokens][:self.max_len]\n",
        "\n",
        "    def pad_sequence(self, seq):\n",
        "        return seq + [0] * (self.max_len - len(seq))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = self.encode_text(self.texts[idx])\n",
        "        padded = self.pad_sequence(encoded)\n",
        "        return torch.tensor(padded), torch.tensor(self.labels[idx])"
      ],
      "metadata": {
        "id": "j7aEizm4m3zG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capsule Layer Architecture"
      ],
      "metadata": {
        "id": "1zSr3Gu9nFQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsuleLayer(nn.Module):\n",
        "    def __init__(self, num_capsules, dim_capsule, input_dim, input_len, routing_iters=3):\n",
        "        super(CapsuleLayer, self).__init__()\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routing_iters = routing_iters\n",
        "        # initializing weight randomly\n",
        "        self.W = nn.Parameter(0.01 * torch.randn(1, input_len, num_capsules, dim_capsule, input_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2).unsqueeze(4)\n",
        "        u_hat = torch.einsum('bijhd,bijdf->bijhf',\n",
        "                     self.W.expand(x.size(0), -1, -1, -1, -1),\n",
        "                     x[:, :self.W.size(2), :, :, :].permute(0, 2, 1, 3, 4).expand(-1, self.W.size(1), -1, -1, -1))\n",
        "        b_ij = torch.zeros_like(u_hat[:, :, :, 0])\n",
        "\n",
        "        for r in range(self.routing_iters):\n",
        "            c_ij = F.softmax(b_ij, dim=2)\n",
        "            s_j = (c_ij.unsqueeze(3) * u_hat).sum(dim=1)\n",
        "            v_j = self.squash(s_j)\n",
        "            if r < self.routing_iters - 1:\n",
        "                delta_b_ij = (u_hat * v_j.unsqueeze(1)).sum(dim=-1)\n",
        "                b_ij = b_ij + delta_b_ij\n",
        "        return v_j\n",
        "\n",
        "    def squash(self, s):\n",
        "        s_norm = torch.norm(s, dim=2, keepdim=True)\n",
        "        return (s_norm**2 / (1 + s_norm**2)) * (s / (s_norm + 1e-8))"
      ],
      "metadata": {
        "id": "Zyi_lTe-nNij"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining Capsule Layer with 2 Convolutional Layers"
      ],
      "metadata": {
        "id": "UwqQXzc_wZDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=32, input_dim=16, input_len=10, output_len = 2):\n",
        "        super(CapsNet, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.conv1 = nn.Conv1d(embedding_dim, 64, kernel_size=9, stride=1)\n",
        "        self.primary_caps = nn.Conv1d(64, input_dim * input_len, kernel_size=9, stride=2)\n",
        "        self.dense_caps = CapsuleLayer(num_capsules=2, dim_capsule=16, input_dim=input_dim, input_len=input_len*6)\n",
        "        for name, param in self.dense_caps.state_dict().items():\n",
        "          print(f\"{name}: shape = {param.shape}\")\n",
        "        self.linear = nn.Linear(512, output_len)\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).transpose(1, 2)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.primary_caps(x).transpose(1, 2).contiguous()\n",
        "        x = x.view(x.size(0), -1, self.input_dim)\n",
        "        x = self.dense_caps(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "3tiLxN_ywh5t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix Related Visualization Function"
      ],
      "metadata": {
        "id": "ywdBF_ON0eou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, labels, output_dir):\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.savefig(os.path.join(output_dir, \"confusion_matrix.png\"))\n",
        "    wandb.log({\"Confusion_Matrix\": wandb.Image(fig)})\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "VXvdgDr50iw4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Function"
      ],
      "metadata": {
        "id": "t-lwBcF08aAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=10, lr=1e-3, output_dir=\".\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for inputs, labels in tqdm(train_loader, desc=\"Training\", unit=\"batch\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(\"Epoch \" + str(epoch+1) + \", Loss: \"  + str(total_loss))\n",
        "        wandb.log({\"epoch\": epoch+1, \"loss\": total_loss})\n",
        "        path = f\"checkpoints/model_epoch_{epoch+1}.pth\"\n",
        "        torch.save(model.state_dict(), path)\n",
        "        wandb_path = f\"model_epoch_{epoch+1}.pth\"\n",
        "        wandb.save(path)\n",
        "        evaluate(model, val_loader, output_dir)"
      ],
      "metadata": {
        "id": "Mcocsk4h1BeZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Function"
      ],
      "metadata": {
        "id": "H0vlR8Ff1Fr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, output_dir):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    all_preds, all_pred_classes, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader, desc=\"Validation\", unit=\"batch\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.softmax(outputs, dim=1)\n",
        "            pred_classes = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_pred_classes.extend(pred_classes.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_pred_classes)\n",
        "    f1 = f1_score(all_labels, all_pred_classes, average='weighted')\n",
        "    auc = roc_auc_score(all_labels, all_preds, multi_class='ovr', average='weighted')\n",
        "    cm = confusion_matrix(all_labels, all_pred_classes)\n",
        "    print(\"Accuracy: \" + str(acc) + \", F1 Score: \" + str(f1) + \", AUC: \" + str(auc))\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    wandb.log({\"accuracy\": acc, \"f1_score\": f1, \"auc\": auc})\n",
        "    plot_confusion_matrix(cm, labels=unique_labels, output_dir=output_dir)"
      ],
      "metadata": {
        "id": "w9zaG-7c1Hpn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "wandb initialiation\n",
        "\n",
        "WANDB API KEY = 655b1cb95fef4a774eef6ab553f1d273a39c3a41"
      ],
      "metadata": {
        "id": "YweZB_t71LaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "wandb.init(project=\"IS 584 Course Term Project\", dir=\"outputs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "DCDxANGh9PXP",
        "outputId": "0ea09b98-cb73-4547-b446-ede1d056a791"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meabu2ss\u001b[0m (\u001b[33meabu2ss-metu-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>outputs/wandb/run-20250524_135409-fffdukge</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project/runs/fffdukge' target=\"_blank\">distinctive-music-40</a></strong> to <a href='https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project' target=\"_blank\">https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project/runs/fffdukge' target=\"_blank\">https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project/runs/fffdukge</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project/runs/fffdukge?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a1621fb8710>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining all previous classes and functions together"
      ],
      "metadata": {
        "id": "LjHqEMO49Qfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = word_tokenize\n",
        "dataset = ArticleDataset(data_clean, tokenizer)\n",
        "train_idx, val_idx = train_test_split(np.arange(len(dataset)), test_size=0.2, random_state = seed, stratify=dataset.labels)\n",
        "train_set = torch.utils.data.Subset(dataset, train_idx)\n",
        "val_set = torch.utils.data.Subset(dataset, val_idx)\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, worker_init_fn=seed_worker, generator=g)\n",
        "\n",
        "input_dim = 3\n",
        "input_len = 4\n",
        "\n",
        "model = CapsNet(vocab_size=len(dataset.vocab), input_dim = input_dim, input_len = input_len, output_len = output_len)\n",
        "\n",
        "lr = 1e-3\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "train_model(model, train_loader, val_loader, epochs=epochs, lr=lr, output_dir=\"outputs\")\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "piRtyFad-fZf",
        "outputId": "c2d3d7a9-433e-49ea-8550-0382d71fc197"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.max_len: 5290\n",
            "W: shape = torch.Size([1, 24, 2, 16, 3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/50 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.79batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.02batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.10batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.21batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.24batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:11,  4.29batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:16,  2.98batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:23,  2.03batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:19,  2.40batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:16,  2.77batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:14,  3.12batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:13,  3.37batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:03<00:11,  3.62batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:12,  3.38batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:12,  3.21batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:13,  2.99batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:16,  2.37batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:18,  2.02batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:20,  1.81batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:20,  1.79batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:16,  2.17batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:13,  2.57batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:11,  2.92batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:10,  3.20batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:08,  3.47batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.66batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.83batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.94batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:06,  4.03batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:09<00:06,  4.11batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:09,  2.61batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:11,  2.11batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:09,  2.50batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:07,  2.88batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.20batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.48batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.73batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  3.80batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:12<00:04,  3.95batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:03,  4.07batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  4.11batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:13<00:03,  4.21batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:13<00:03,  4.25batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:02,  4.29batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:14<00:02,  4.27batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:03,  2.68batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:04,  2.15batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:15<00:03,  2.48batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:02,  2.85batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.19batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:16<00:01,  3.47batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:16<00:01,  3.64batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  3.69batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:17<00:00,  3.33batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  2.60batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  3.03batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 75.63790726661682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:08,  1.58batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:07,  1.60batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:07,  1.53batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:02<00:04,  2.13batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:03,  2.75batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  3.30batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  3.84batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  4.30batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  4.67batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:00,  4.90batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  5.06batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.14batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.23batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.58batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4341216216216216, F1 Score: 0.3281255117521996, AUC: 0.6804252848165874\n",
            "Confusion Matrix:\n",
            " [[125   0   0   0   0   0 612]\n",
            " [  0   0   0   0   0   0  12]\n",
            " [ 12   0   0   0   0   0 289]\n",
            " [  0   0   0   0   0   0  22]\n",
            " [  0   0   0   0   0   0  10]\n",
            " [  4   0   0   0   0   0  23]\n",
            " [ 21   0   0   0   0   0 646]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   2%|▏         | 1/50 [00:23<19:01, 23.30s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:36,  1.51batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:22,  2.42batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:17,  2.99batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:15,  3.37batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:14,  3.62batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:13,  3.80batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:12,  3.96batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:18,  2.55batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:23,  2.04batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:19,  2.41batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:16,  2.73batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:14,  3.05batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:12,  3.34batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.58batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:11,  3.70batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:20,  1.99batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:17,  2.19batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:14,  2.54batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:12,  2.85batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:12,  2.79batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:12,  2.79batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:12,  2.82batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:11,  2.78batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:11,  2.71batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:14,  2.15batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:10<00:17,  1.67batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:15,  1.81batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:12,  2.20batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:11<00:10,  2.55batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:08,  2.92batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:07,  3.23batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:06,  3.50batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:06,  3.71batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:05,  3.89batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  4.03batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:04,  4.11batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:04,  4.17batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:07,  2.29batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:07,  2.18batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:06,  2.54batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:05,  2.91batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:04,  3.24batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:03,  3.45batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.66batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  3.82batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:02,  3.97batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  4.02batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:01,  4.12batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  2.51batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:02,  2.11batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.49batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.82batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.15batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.44batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.70batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.91batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 65.75995671749115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.54batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.55batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.08batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:02,  4.00batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:03,  2.70batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.35batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:03,  2.04batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:02,  2.12batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:02,  1.73batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:04<00:01,  2.19batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  2.68batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  3.06batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  3.57batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.90batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5777027027027027, F1 Score: 0.5143355093076835, AUC: 0.7100047649086494\n",
            "Confusion Matrix:\n",
            " [[481   0   0   0   0   0 256]\n",
            " [  3   0   0   0   0   0   9]\n",
            " [ 53   0   0   0   0   0 248]\n",
            " [  3   0   0   0   0   0  19]\n",
            " [  2   0   0   0   0   0   8]\n",
            " [ 10   0   0   0   0   0  17]\n",
            " [122   0   0   0   0   0 545]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   4%|▍         | 2/50 [00:47<19:11, 23.99s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.00batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.79batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.99batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.13batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:16,  3.04batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:26,  1.92batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:21,  2.32batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:17,  2.72batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:15,  3.04batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.32batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.53batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.76batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:10,  3.92batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  4.02batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  4.08batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:20,  1.94batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:17,  2.23batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:14,  2.61batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:12,  2.96batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:10,  3.29batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:09,  3.56batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:09,  3.74batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:08,  3.87batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:08,  3.98batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:07<00:07,  4.00batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:07,  4.09batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:08,  3.28batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:11,  2.54batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:12,  2.16batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:13,  1.92batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:12,  1.94batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:13,  1.80batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:10,  2.17batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:08,  2.53batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:07,  2.89batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:06,  3.23batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.53batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  3.71batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.92batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:03,  4.03batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  4.13batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:04,  2.92batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:06,  2.09batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:04,  2.43batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  2.79batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:03,  3.11batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:02,  3.40batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.57batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.76batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.92batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:16<00:01,  4.06batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:00,  4.06batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.05batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.22batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  2.55batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  2.96batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 58.40214377641678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.43batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.69batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.90batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.90batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.89batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.94batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.75batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.83batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.86batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  5.84batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  3.87batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:02<00:00,  3.18batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  2.50batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.87batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6188063063063063, F1 Score: 0.5492612760423932, AUC: 0.7588985326425212\n",
            "Confusion Matrix:\n",
            " [[586   0   0   0   0   0 151]\n",
            " [  5   0   0   0   0   0   7]\n",
            " [ 67   0   0   0   0   0 234]\n",
            " [  5   0   0   0   0   0  17]\n",
            " [  2   0   0   0   0   0   8]\n",
            " [ 11   0   0   0   0   0  16]\n",
            " [154   0   0   0   0   0 513]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   6%|▌         | 3/50 [01:12<18:54, 24.14s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:28,  1.96batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:34,  1.57batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:32,  1.63batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:03<00:48,  1.08batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:03<00:35,  1.46batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:03<00:26,  1.87batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:03<00:21,  2.30batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:04<00:17,  2.71batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:04<00:15,  3.05batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:13,  3.37batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:12,  3.61batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:05<00:11,  3.82batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:11,  3.81batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:06<00:18,  2.22batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:06<00:19,  2.13batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:07<00:15,  2.52batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:07<00:13,  2.90batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:07<00:11,  3.20batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:10,  3.49batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:09,  3.71batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:09,  3.85batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:08,  3.89batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:08,  4.02batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:07,  4.10batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:10,  3.09batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:10<00:14,  2.07batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:12,  2.42batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:11,  2.52batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:11<00:10,  2.58batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:09,  2.63batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:09,  2.69batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:12<00:09,  2.56batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:10,  2.24batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:13<00:11,  1.99batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:14<00:12,  1.73batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:14<00:09,  2.12batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:14<00:07,  2.51batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:15<00:06,  2.88batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:15<00:05,  3.21batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:15<00:04,  3.47batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:15<00:04,  3.63batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:03,  3.79batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:16<00:03,  3.91batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:02,  4.04batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:02,  4.11batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:17<00:05,  2.00batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:18<00:03,  2.25batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:18<00:03,  2.63batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:18<00:02,  2.96batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:01,  3.23batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  3.51batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:01,  3.75batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:00,  3.93batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  4.05batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  4.13batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.80batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 53.04644465446472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  6.03batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.50batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  3.86batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:05,  1.87batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:03,  2.35batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  2.95batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  3.54batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  4.06batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  4.50batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  4.74batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  4.96batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.17batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.32batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.77batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6233108108108109, F1 Score: 0.5527796293569164, AUC: 0.7667353993188039\n",
            "Confusion Matrix:\n",
            " [[597   0   0   0   0   0 140]\n",
            " [  5   0   0   0   0   0   7]\n",
            " [ 72   0   0   0   0   0 229]\n",
            " [  4   0   0   0   0   0  18]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [ 10   0   0   0   0   0  17]\n",
            " [157   0   0   0   0   0 510]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   8%|▊         | 4/50 [01:36<18:40, 24.36s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:39,  1.41batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:38,  1.42batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:02<00:34,  1.52batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:02<00:25,  2.05batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:20,  2.49batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:17,  2.92batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:15,  3.26batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:13,  3.55batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:12,  3.76batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:11,  3.90batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:21,  2.05batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:05<00:20,  2.18batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:17,  2.53batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:15,  2.80batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:13,  3.10batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:11,  3.39batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:10,  3.62batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:10,  3.76batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:09,  3.89batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:08,  4.02batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:08,  4.07batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:17,  1.98batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:14,  2.26batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:12,  2.62batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:10,  2.95batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:09,  3.26batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:08,  3.54batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.69batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:06,  3.89batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  4.00batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  4.06batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:05,  4.08batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:10,  2.16batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:11,  1.93batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:09,  2.13batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:13<00:08,  2.29batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:07,  2.42batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:07,  2.48batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:06,  2.57batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:06,  2.52batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:15<00:07,  1.89batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:07,  1.88batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:16<00:05,  2.25batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:04,  2.63batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:03,  2.98batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:03,  3.31batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:02,  3.50batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  3.71batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:01,  3.88batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:02,  2.72batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.04batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:01,  2.40batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  2.77batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  3.10batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.39batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.79batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 48.498910427093506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.98batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.83batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.75batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.71batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.72batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.63batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.47batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:02,  2.79batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:02,  2.34batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  2.86batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  3.35batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  3.75batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.16batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  4.05batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6266891891891891, F1 Score: 0.5583055166209688, AUC: 0.7652002949527471\n",
            "Confusion Matrix:\n",
            " [[550   0   0   0   0   0 187]\n",
            " [  5   0   0   0   0   0   7]\n",
            " [ 53   0   0   0   0   0 248]\n",
            " [  2   0   0   0   0   0  20]\n",
            " [  2   0   0   0   0   0   8]\n",
            " [ 10   0   0   0   0   0  17]\n",
            " [104   0   0   0   0   0 563]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  10%|█         | 5/50 [02:00<18:08, 24.19s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.08batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.99batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.05batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.72batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:15,  3.22batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:16,  3.05batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:21,  2.31batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:23,  2.05batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:24,  1.92batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:28,  1.62batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:22,  1.98batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:18,  2.37batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:15,  2.75batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:13,  3.10batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:12,  3.33batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:11,  3.58batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:10,  3.75batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:09,  3.92batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:09,  4.04batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:08,  4.11batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:15,  2.29batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:15,  2.15batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:13,  2.50batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:11,  2.81batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:09,  3.16batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.44batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.66batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.85batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:13,  2.03batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:12,  2.16batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:09,  2.53batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:08,  2.88batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:07,  3.21batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:06,  3.47batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.69batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.87batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.95batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  4.00batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  4.11batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:03,  4.16batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:04,  3.10batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:05,  2.38batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:06,  2.01batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:06,  1.78batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:06,  1.83batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:04,  2.01batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:03,  2.34batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  2.71batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  3.06batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.38batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  3.64batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  3.84batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.98batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  4.09batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.26batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.80batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 44.49198001623154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.30batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.49batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.63batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.60batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.48batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.55batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.51batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.49batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.52batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  5.54batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:01<00:00,  5.46batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:02<00:00,  5.38batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:02<00:00,  5.47batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  4.43batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6199324324324325, F1 Score: 0.5553735710209744, AUC: 0.7575464080732178\n",
            "Confusion Matrix:\n",
            " [[551   0   1   0   0   0 185]\n",
            " [  5   0   0   0   0   0   7]\n",
            " [ 57   0   3   0   0   0 241]\n",
            " [  2   0   0   0   0   0  20]\n",
            " [  2   0   0   0   0   0   8]\n",
            " [  9   0   0   0   0   0  18]\n",
            " [115   0   5   0   0   0 547]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  12%|█▏        | 6/50 [02:24<17:39, 24.08s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.08batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.03batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.10batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.12batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.21batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:11,  4.23batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.28batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.31batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:20,  2.27batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:21,  2.13batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:20,  2.18batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:19,  2.31batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:17,  2.41batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:16,  2.51batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:16,  2.45batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:18,  2.13batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:22,  1.73batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:07<00:20,  1.88batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:16,  2.24batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:13,  2.60batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:11,  2.92batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:10,  3.23batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:09,  3.51batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:08,  3.73batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:08,  3.77batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:07,  3.91batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  4.01batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:06,  4.09batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:06,  4.12batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  4.15batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:10,  2.36batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:11,  2.16batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:09,  2.54batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:07,  2.89batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.23batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.51batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.72batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  3.86batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.91batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:03,  4.01batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  4.09batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:13<00:03,  4.15batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  4.12batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:02,  4.18batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:14<00:02,  4.20batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:03,  2.88batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:04,  2.14batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:03,  2.49batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:02,  2.58batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:02,  2.65batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  2.68batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  2.68batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:01,  2.74batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.20batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  1.93batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 39.40107053518295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  6.01batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.62batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.64batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.43batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.45batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.51batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.47batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.35batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.42batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  5.48batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  5.45batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:02<00:00,  5.50batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  2.08batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.95batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5974099099099099, F1 Score: 0.5399048873461625, AUC: 0.7510858109816336\n",
            "Confusion Matrix:\n",
            " [[605   0  10   0   0   0 122]\n",
            " [  4   0   1   0   0   0   7]\n",
            " [ 85   0   8   0   0   0 208]\n",
            " [  9   0   0   0   0   0  13]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  9   0   0   0   0   0  18]\n",
            " [187   0  32   0   0   0 448]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  14%|█▍        | 7/50 [02:48<17:11, 24.00s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  3.98batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.14batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.26batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.27batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:11,  4.29batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:11,  4.30batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.24batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.29batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:19,  2.45batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:21,  2.15batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:17,  2.54batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:15,  2.88batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:03<00:13,  3.21batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:12,  3.48batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:11,  3.68batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.84batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:04<00:09,  3.98batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:09,  4.05batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:05<00:10,  3.67batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:05<00:12,  2.93batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:14,  2.46batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:16,  2.03batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:18,  1.80batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:19,  1.66batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:15,  2.01batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:12,  2.39batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:10,  2.76batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.12batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:07,  3.40batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:07,  3.55batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.74batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:06,  3.87batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:10<00:05,  4.01batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:05,  4.03batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:11<00:05,  4.10batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:11<00:04,  4.14batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:11<00:06,  3.12batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:08,  2.02batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:07,  2.38batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:05,  2.75batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:04,  3.11batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:13<00:04,  3.42batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.61batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:03,  3.76batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:14<00:02,  3.90batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:14<00:02,  4.02batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:14<00:02,  4.08batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:15<00:01,  4.11batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:03,  2.27batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:02,  2.17batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:16<00:01,  2.51batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  2.84batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  3.17batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:17<00:00,  3.45batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:17<00:00,  3.65batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:17<00:00,  3.12batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 34.30833277106285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.50batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  4.49batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  3.89batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:02,  3.42batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:03,  2.47batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.21batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:03,  2.01batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:03,  1.61batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:02,  2.06batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:04<00:01,  2.55batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:00,  3.06batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  3.49batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  3.93batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.92batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.589527027027027, F1 Score: 0.5497829945782591, AUC: 0.7487683465475337\n",
            "Confusion Matrix:\n",
            " [[552   0  23   0   0   0 162]\n",
            " [  4   0   0   0   0   0   8]\n",
            " [ 63   0  24   0   0   0 214]\n",
            " [  5   0   1   0   0   0  16]\n",
            " [  2   0   0   0   0   0   8]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [139   0  57   0   0   0 471]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  16%|█▌        | 8/50 [03:11<16:35, 23.71s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  3.98batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.03batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.18batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.19batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:17,  2.86batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:25,  1.93batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:20,  2.35batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:17,  2.74batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:15,  3.08batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.37batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.52batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.72batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.86batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:14,  2.97batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:20,  2.02batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:17,  2.33batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:14,  2.69batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:12,  3.04batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:11,  3.32batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:10,  3.51batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:09,  3.70batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:15,  2.16batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:15,  2.09batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:14,  2.25batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:12,  2.39batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:12,  2.50batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:11,  2.55batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:17,  1.57batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:11<00:18,  1.45batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:12<00:16,  1.53batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:12<00:13,  1.90batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:12<00:10,  2.27batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:13<00:08,  2.66batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:13<00:07,  3.00batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:13<00:06,  3.28batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:13<00:05,  3.54batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:05,  3.67batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:14<00:04,  3.84batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:04,  3.93batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:04,  3.29batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:15<00:07,  1.96batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:16<00:06,  2.31batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:16<00:04,  2.67batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:03,  3.01batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:03,  3.33batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:17<00:02,  3.51batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:02,  3.73batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  3.88batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:01,  4.01batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:01,  3.99batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  4.04batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:01,  2.43batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  2.16batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.51batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:20<00:00,  2.80batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.76batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 29.824122369289398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.86batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.89batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.93batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.81batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  4.80batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  4.17batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  3.67batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.86batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  2.52batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:01,  2.20batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:01,  2.02batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:01,  1.94batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  2.41batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.98batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5844594594594594, F1 Score: 0.5576082943859029, AUC: 0.7466389937385443\n",
            "Confusion Matrix:\n",
            " [[542   0  40   0   0   0 155]\n",
            " [  4   0   0   0   0   0   8]\n",
            " [ 57   0  42   0   0   0 202]\n",
            " [  5   0   1   0   0   0  16]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [123   0  90   0   0   0 454]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  18%|█▊        | 9/50 [03:36<16:32, 24.20s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.00batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.09batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.16batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.27batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.19batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:11,  4.22batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.26batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.22batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:24,  1.94batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:20,  2.27batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:16,  2.65batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:14,  2.99batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:13,  3.30batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:12,  3.46batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:11,  3.66batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.85batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:04<00:09,  3.97batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:09,  3.99batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:17,  2.10batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:16,  2.13batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:14,  2.48batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:12,  2.82batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:10,  3.10batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:09,  3.41batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:07<00:08,  3.66batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:07,  3.85batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:07,  3.84batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:08<00:07,  3.94batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:08<00:06,  3.93batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:09<00:09,  2.73batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:11,  2.21batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:12,  1.92batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:12,  1.91batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:12,  1.75batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:10,  1.94batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:08,  2.30batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:07,  2.67batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:06,  2.97batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:05,  3.30batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.50batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:04,  3.70batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.85batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.96batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:02,  4.05batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:04,  2.50batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:04,  2.10batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:03,  2.44batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  2.82batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:02,  3.08batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.38batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.60batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.77batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  3.93batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:17<00:00,  4.02batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  4.10batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  3.07batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 25.492875069379807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:12,  1.04batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:06,  1.99batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:03,  2.77batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:02,  3.42batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.95batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  4.44batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  4.82batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  5.07batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:00,  5.17batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  5.30batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  5.30batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:02<00:00,  5.39batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.43batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  4.23batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5720720720720721, F1 Score: 0.5481261156711744, AUC: 0.741045435742888\n",
            "Confusion Matrix:\n",
            " [[587   0  38   0   0   2 110]\n",
            " [  4   0   1   0   0   0   7]\n",
            " [ 75   0  54   0   0   1 171]\n",
            " [  7   0   3   0   0   0  12]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  9   0   4   0   0   0  14]\n",
            " [168   0 121   0   0   3 375]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  20%|██        | 10/50 [03:59<15:47, 23.69s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:37,  1.48batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:37,  1.44batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:02<00:35,  1.48batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:02<00:33,  1.56batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:25,  2.02batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:03<00:20,  2.47batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:03<00:17,  2.87batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:15,  3.17batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:13,  3.46batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:12,  3.67batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:11,  3.83batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:11,  3.89batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:10,  3.97batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  4.06batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:09,  4.13batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:09,  4.18batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:19,  2.00batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:17,  2.23batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:14,  2.59batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:12,  2.93batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:10,  3.18batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:09,  3.46batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:08,  3.71batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:08,  3.90batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:07,  4.02batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:07,  4.05batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  4.11batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:11,  2.47batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:12,  2.13batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:10,  2.47batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:08,  2.84batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:07,  3.15batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:06,  3.42batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:06,  3.63batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:11<00:05,  3.72batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.85batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.97batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  4.05batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:05,  2.95batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:07,  2.25batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:07,  1.95batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:07,  1.78batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:08,  1.61batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:06,  1.97batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:04,  2.35batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:03,  2.69batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.04batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  3.31batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:01,  3.58batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.79batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.92batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  3.96batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  4.04batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  4.13batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  4.17batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  2.97batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 21.536451905965805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:09,  1.39batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:06,  1.81batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:05,  2.05batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:03,  2.72batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.34batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  3.91batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  4.24batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  4.60batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  4.91batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  5.04batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  5.04batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.08batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.18batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.92batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5658783783783784, F1 Score: 0.5464346005597698, AUC: 0.7393803350740488\n",
            "Confusion Matrix:\n",
            " [[559   0  44   0   0   1 133]\n",
            " [  4   0   1   0   0   0   7]\n",
            " [ 74   0  62   0   0   1 164]\n",
            " [  7   0   3   0   0   0  12]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   6   0   0   0  13]\n",
            " [156   0 125   0   0   2 384]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  22%|██▏       | 11/50 [04:23<15:25, 23.74s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.80batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.87batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.03batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.14batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.22batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:11,  4.18batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.19batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.22batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:12,  3.62batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:02<00:18,  2.53batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:20,  2.18batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:22,  1.97batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:23,  1.83batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:23,  1.80batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:18,  2.17batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:15,  2.52batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:13,  2.89batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:11,  3.19batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:10,  3.46batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:10,  3.60batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:09,  3.79batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:08,  3.95batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:08,  4.06batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:13,  2.29batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:13,  2.37batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:11,  2.56batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:09,  2.91batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.22batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:07,  3.44batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:07,  3.66batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.83batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:06,  3.97batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:10<00:05,  4.05batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:10<00:05,  4.11batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:11<00:05,  4.17batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:11<00:07,  2.68batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:09,  2.06batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:07,  2.39batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:06,  2.75batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:05,  3.07batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:04,  3.37batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:13<00:03,  3.59batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.77batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:03,  3.91batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:14<00:02,  4.00batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:14<00:02,  4.03batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:02,  3.19batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:15<00:03,  2.48batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:03,  2.09batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:03,  1.85batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:02,  1.74batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:02,  1.86batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.24batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.62batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.96batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.92batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 17.560611307621002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.64batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.71batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.77batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.66batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.50batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.30batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.43batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.48batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.51batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  5.29batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:01,  2.10batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.53batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  3.02batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.97batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5489864864864865, F1 Score: 0.5463741514930356, AUC: 0.7408380158251007\n",
            "Confusion Matrix:\n",
            " [[529   0  67   0   0   7 134]\n",
            " [  3   0   3   0   0   0   6]\n",
            " [ 58   0  92   0   0   5 146]\n",
            " [  5   0   5   0   0   1  11]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   4   0   0   1  14]\n",
            " [119   0 189   0   0   6 353]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  24%|██▍       | 12/50 [04:46<14:53, 23.52s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.07batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.05batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.01batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.08batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.16batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:11,  4.17batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:21,  2.26batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:22,  2.10batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:19,  2.45batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:16,  2.77batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:14,  3.09batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:12,  3.41batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.65batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.81batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.90batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:09,  4.02batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:09,  4.11batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:10,  3.56batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:05<00:11,  3.28batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:14,  2.45batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:17,  2.04batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:18,  1.81batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:20,  1.61batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:16,  1.98batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:13,  2.37batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:10,  2.75batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:09,  3.10batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.33batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:07,  3.55batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.74batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.88batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:06,  4.00batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:11,  1.95batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:10,  2.19batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:08,  2.48batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:07,  2.83batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:06,  3.12batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:05,  3.40batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.63batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.82batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  3.85batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.96batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:05,  2.48batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:05,  2.05batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:04,  2.42batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:03,  2.74batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.09batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.38batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.61batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.71batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.80batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.94batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  4.03batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.07batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  2.37batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.92batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 13.420203134417534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:08,  1.60batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:07,  1.57batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:05,  2.06batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:04,  2.36batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:03,  2.88batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  3.44batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  3.91batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  4.32batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  4.61batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:00,  4.84batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  5.01batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.17batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.30batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.57batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5484234234234234, F1 Score: 0.5378259224308498, AUC: 0.7304685470342525\n",
            "Confusion Matrix:\n",
            " [[529   0  50   0   0  10 148]\n",
            " [  4   0   4   0   0   0   4]\n",
            " [ 65   0  61   0   0   3 172]\n",
            " [  6   0   1   0   0   1  14]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   4   0   0   1  14]\n",
            " [128   0 147   0   0   9 383]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  26%|██▌       | 13/50 [05:10<14:38, 23.76s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.06batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.02batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.96batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.97batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.13batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.18batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.19batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:25,  1.88batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:20,  2.21batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:17,  2.59batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:14,  2.95batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:13,  3.22batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:12,  3.48batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:11,  3.70batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.82batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:21,  1.83batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:17,  2.21batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:14,  2.58batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:12,  2.91batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:11,  3.15batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:11,  2.99batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:11,  2.92batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:11,  2.88batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:11,  2.78batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:13,  2.23batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:14,  1.96batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:15,  1.84batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:14,  1.89batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:11,  2.26batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:09,  2.59batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:08,  2.95batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:07,  3.24batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:06,  3.53batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.70batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.87batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.98batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  4.02batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:05,  2.84batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:07,  2.11batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:06,  2.46batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:04,  2.83batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  3.17batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.43batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.59batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.76batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.91batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.11batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:03,  1.94batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:02,  2.29batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  2.61batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.95batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.27batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.50batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  3.75batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.94batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 11.063472889363766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.69batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.72batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.55batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:02,  3.98batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:03,  2.86batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.26batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:03,  2.08batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:03,  1.98batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:02,  1.84batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:04<00:01,  2.14batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  2.63batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  3.14batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  3.60batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.91batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5394144144144144, F1 Score: 0.534137007679281, AUC: 0.7256083501222551\n",
            "Confusion Matrix:\n",
            " [[543   0  61   0   0  11 122]\n",
            " [  4   0   4   0   0   0   4]\n",
            " [ 72   0  95   1   0   6 127]\n",
            " [  5   0   5   0   0   1  11]\n",
            " [  3   0   3   0   0   0   4]\n",
            " [  9   0   6   0   0   0  12]\n",
            " [151   0 186   0   0  10 320]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  28%|██▊       | 14/50 [05:34<14:20, 23.89s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.04batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.12batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.99batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.05batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.09batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.15batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.12batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:23,  2.03batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:21,  2.17batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:17,  2.57batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:15,  2.93batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:13,  3.21batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:12,  3.48batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.70batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.88batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:09,  4.02batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:19,  1.97batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:17,  2.22batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:14,  2.58batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:12,  2.88batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:11,  3.15batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:09,  3.42batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:09,  3.64batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:08,  3.81batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:07<00:07,  3.90batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:07,  3.99batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:07,  4.01batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:08<00:09,  2.85batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:11,  2.29batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:13,  1.92batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:14,  1.73batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:12,  1.94batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:10,  2.13batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:08,  2.45batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:07,  2.77batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:06,  3.08batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.37batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:05,  3.58batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.79batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:08,  1.98batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:06,  2.18batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:05,  2.50batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  2.81batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.00batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.29batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.52batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.73batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.82batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.94batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  4.03batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  2.82batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.04batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.36batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.69batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  3.03batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.93batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 9.318254373967648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  6.01batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.54batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.71batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.68batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.71batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.80batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.81batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.62batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.60batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  5.57batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:01<00:00,  5.49batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:02<00:00,  5.47batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:02<00:00,  5.19batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:02<00:00,  5.04batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5275900900900901, F1 Score: 0.5242687827171851, AUC: 0.7268112781069982\n",
            "Confusion Matrix:\n",
            " [[537   0  64   6   0   9 121]\n",
            " [  4   0   3   0   0   0   5]\n",
            " [ 66   0  80   3   0   5 147]\n",
            " [  4   0   4   0   0   1  13]\n",
            " [  3   0   2   0   0   0   5]\n",
            " [  9   0   4   0   0   1  13]\n",
            " [147   0 184   4   0  13 319]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  30%|███       | 15/50 [05:57<13:45, 23.57s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:34,  1.61batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:33,  1.61batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:33,  1.59batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:02<00:27,  1.92batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:21,  2.36batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:17,  2.79batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:15,  3.12batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:14,  3.42batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:12,  3.65batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:12,  3.83batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:11,  3.95batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:21,  2.02batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:19,  2.18batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:16,  2.57batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:14,  2.92batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:12,  3.20batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:11,  3.46batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:10,  3.68batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:09,  3.83batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:09,  3.97batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:08,  4.05batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:08,  4.10batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:11,  2.83batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:15,  2.06batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:13,  2.38batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:11,  2.68batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:09,  3.01batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.31batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:07,  3.56batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.75batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.86batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:06,  3.97batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:05,  4.05batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:10,  2.00batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:10,  1.96batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:09,  2.16batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:08,  2.31batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:07,  2.45batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:06,  2.53batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:06,  2.56batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:05,  2.62batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:06,  2.08batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:16<00:07,  1.74batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:05,  2.09batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:04,  2.48batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:17<00:03,  2.84batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:02,  3.17batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  3.39batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:01,  3.62batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.79batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  2.96batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:01,  2.11batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  2.34batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.71batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:20<00:00,  3.05batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.77batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 8.586215063929558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.74batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.38batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.50batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.48batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.03batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.12batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  2.63batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  3.04batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  3.57batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  4.01batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  4.34batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.63batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.89batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.93batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5512387387387387, F1 Score: 0.5351210099550686, AUC: 0.7265547717240919\n",
            "Confusion Matrix:\n",
            " [[533   0  39   3   0   5 157]\n",
            " [  4   0   1   0   0   0   7]\n",
            " [ 64   0  53   1   0   5 178]\n",
            " [  5   0   1   0   0   1  15]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [ 10   0   2   0   0   0  15]\n",
            " [140   0 127   1   0   6 393]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  32%|███▏      | 16/50 [06:21<13:26, 23.73s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:42,  1.29batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:34,  1.55batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:02<00:35,  1.48batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:02<00:28,  1.82batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:24,  2.04batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:03<00:22,  2.24batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:03<00:20,  2.40batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:19,  2.50batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:04<00:16,  2.82batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:14,  3.14batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:13,  3.42batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:12,  3.63batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:21,  1.97batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:06<00:19,  2.10batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:06<00:16,  2.44batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:14,  2.80batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:07<00:12,  3.08batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:07<00:11,  3.37batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:10,  3.61batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:09,  3.80batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:08,  3.90batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:08,  3.96batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:08,  4.04batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:07,  4.09batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:16,  1.86batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:10<00:13,  2.19batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:11,  2.57batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:09,  2.93batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:08,  3.23batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:07,  3.45batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:06,  3.64batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:06,  3.78batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:05,  3.90batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:05,  4.00batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:13<00:11,  1.88batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:13<00:08,  2.23batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:07,  2.55batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:06,  2.90batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:05,  2.84batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:05,  2.85batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:15<00:05,  2.83batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:05,  2.75batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  2.75batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:04,  2.60batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:05,  2.20batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:17<00:04,  2.22batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:18<00:04,  1.87batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:18<00:03,  2.24batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:18<00:02,  2.61batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:02,  2.94batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  3.24batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:01,  3.51batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:00,  3.63batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  3.81batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.93batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.79batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 8.140931662172079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.81batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.51batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.61batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.65batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.14batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.10batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  2.63batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  3.14batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  3.66batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  4.12batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  4.44batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.73batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.93batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.98batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5444819819819819, F1 Score: 0.5386437962052415, AUC: 0.7243526408013048\n",
            "Confusion Matrix:\n",
            " [[546   0  49   2   0  12 128]\n",
            " [  4   0   3   0   0   0   5]\n",
            " [ 67   0  81   1   0   6 146]\n",
            " [  5   0   4   0   0   1  12]\n",
            " [  4   0   0   0   0   0   6]\n",
            " [  6   0   5   0   0   2  14]\n",
            " [143   0 166   3   0  17 338]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  34%|███▍      | 17/50 [06:45<13:05, 23.79s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.91batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:16,  3.19batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:33,  1.56batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:25,  2.08batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:20,  2.54batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:17,  2.93batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:14,  3.29batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:13,  3.50batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:13,  3.52batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:14,  3.23batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:15,  2.97batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:18,  2.37batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:20,  2.05batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:20,  2.02batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:06<00:25,  1.63batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:20,  1.97batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:07<00:17,  2.29batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:07<00:14,  2.64batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:12,  2.98batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:11,  3.27batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:10,  3.44batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:09<00:16,  2.06batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:09<00:15,  2.06batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:09<00:13,  2.40batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:11,  2.75batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:10<00:09,  3.08batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:08,  3.34batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:07,  3.61batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:07,  3.79batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:06,  3.84batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:06,  3.94batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:05,  4.01batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:05,  4.09batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:05,  4.02batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:13<00:09,  2.16batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:13<00:09,  2.17batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:07,  2.54batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:14<00:06,  2.88batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:05,  3.15batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:04,  3.42batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:04,  3.63batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.81batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:03,  3.86batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.99batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  4.06batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  4.13batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.78batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  2.92batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:03,  2.31batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:03,  1.94batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  1.78batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:02,  1.72batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  2.10batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.48batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:20<00:00,  2.86batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.77batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 7.049520835280418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.10batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.43batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.49batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.47batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.55batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  2.72batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  2.43batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.87batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  3.39batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  3.85batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  4.21batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.55batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.77batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.98batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5506756756756757, F1 Score: 0.5388382834081212, AUC: 0.7274615777593499\n",
            "Confusion Matrix:\n",
            " [[561   0  42   0   0  12 122]\n",
            " [  4   0   1   0   0   0   7]\n",
            " [ 70   0  72   0   0  12 147]\n",
            " [  6   0   3   0   0   0  13]\n",
            " [  5   0   0   0   0   0   5]\n",
            " [  9   0   3   0   0   0  15]\n",
            " [160   0 150   0   0  12 345]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  36%|███▌      | 18/50 [07:09<12:43, 23.87s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:27,  1.97batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:40,  1.34batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:27,  1.91batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:21,  2.43batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:17,  2.88batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:15,  3.26batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:14,  3.49batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:12,  3.75batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:11,  3.93batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:11,  4.03batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:10,  4.10batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:10,  4.13batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:10,  4.19batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:09,  4.22batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:13,  3.05batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:15,  2.61batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:16,  2.29batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:18,  2.10batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:18,  1.96batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:16,  2.13batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:15,  2.27batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:13,  2.44batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:11,  2.81batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:10,  3.09batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:09,  3.36batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.57batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.73batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.85batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:06,  3.95batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:12,  2.01batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:11,  2.15batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:09,  2.53batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:07,  2.89batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:06,  3.19batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.44batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.65batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.81batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  3.95batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.92batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:07,  2.25batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:07,  2.11batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:05,  2.48batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  2.83batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.14batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.42batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.65batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:02,  3.78batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.77batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.85batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.95batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.36batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.01batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.12batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.27batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.40batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 5.5560886189341545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:04,  3.22batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:04,  2.68batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:04,  2.34batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:04,  2.01batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:04,  1.88batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.16batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  2.67batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:01,  3.21batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  3.74batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:00,  4.18batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  4.53batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.80batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  4.88batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  3.34batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5456081081081081, F1 Score: 0.5321360876135157, AUC: 0.7261182791994188\n",
            "Confusion Matrix:\n",
            " [[551   0  36   0   0   9 141]\n",
            " [  5   0   2   0   0   0   5]\n",
            " [ 72   0  66   0   0  11 152]\n",
            " [  7   0   2   0   0   0  13]\n",
            " [  4   0   0   0   0   1   5]\n",
            " [  9   0   2   0   0   0  16]\n",
            " [162   0 139   0   0  14 352]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  38%|███▊      | 19/50 [07:33<12:20, 23.90s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.85batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.90batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.10batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:23,  2.21batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:26,  1.94batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:21,  2.36batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:18,  2.69batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:15,  3.05batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:14,  3.30batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.54batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.67batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.84batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:10,  3.96batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  4.06batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.86batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:18,  2.11batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:17,  2.25batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:14,  2.62batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:12,  2.96batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:11,  3.24batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:09,  3.51batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:09,  3.74batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:09,  3.39batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:10,  3.18batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:10,  2.97batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:11,  2.53batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:14,  2.06batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:14,  1.92batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:15,  1.75batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:12,  2.11batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:10,  2.49batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:08,  2.84batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:07,  3.16batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:06,  3.39batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.66batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.81batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.92batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  3.98batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:08,  1.95batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:07,  2.28batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:05,  2.67batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:04,  3.01batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.33batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.57batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  3.79batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.91batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:02,  3.96batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:04,  1.91batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:03,  2.28batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:02,  2.59batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  2.94batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  3.25batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.50batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.66batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  3.79batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  2.97batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 4.5722747799009085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.65batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:08,  1.44batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:06,  1.62batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:02<00:04,  2.00batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:03,  2.30batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.60batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  2.84batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:02,  2.98batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  3.01batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:01,  3.09batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  2.73batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:05<00:01,  1.78batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:05<00:00,  2.20batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:05<00:00,  2.44batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5512387387387387, F1 Score: 0.5441972447432588, AUC: 0.7266232274585936\n",
            "Confusion Matrix:\n",
            " [[540   0  43   2   0   7 145]\n",
            " [  4   0   3   0   0   0   5]\n",
            " [ 58   0  84   1   0  11 147]\n",
            " [  5   0   3   0   0   1  13]\n",
            " [  4   0   0   0   0   0   6]\n",
            " [  8   0   4   0   0   0  15]\n",
            " [140   0 161   2   0   9 355]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  40%|████      | 20/50 [07:58<12:06, 24.22s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  4.03batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.92batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.04batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.12batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.13batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.12batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.20batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:23,  2.04batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:21,  2.20batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:17,  2.58batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:15,  2.88batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:13,  3.19batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:12,  3.45batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.66batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.81batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.93batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:09,  4.00batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:09,  4.08batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:05<00:08,  4.14batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:18,  1.94batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:15,  2.23batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:13,  2.54batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:11,  2.84batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:10,  3.11batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:07<00:09,  3.40batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:08,  3.63batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:08,  3.31batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:08<00:08,  3.12batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:09,  2.85batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:12,  2.15batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:13,  1.90batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:16,  1.48batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:12,  1.81batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:10,  2.19batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:08,  2.55batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:06,  2.93batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.26batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:05,  3.52batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.72batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.86batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  3.94batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:07,  1.91batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:05,  2.28batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:04,  2.66batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.02batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:03,  3.32batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.50batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.68batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.83batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.96batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.99batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:00,  4.01batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.54batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.10batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.45batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.92batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 4.083646224811673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.69batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.70batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.70batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.60batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.57batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.47batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.55batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.55batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.57batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  4.32batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  3.40batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:02<00:00,  2.86batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  2.49batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.53batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5506756756756757, F1 Score: 0.5371365421737483, AUC: 0.7238514457373217\n",
            "Confusion Matrix:\n",
            " [[556   0  34   1   0   9 137]\n",
            " [  4   0   0   0   0   0   8]\n",
            " [ 67   0  63   3   0   7 161]\n",
            " [  6   0   2   0   0   1  13]\n",
            " [  4   0   0   0   0   0   6]\n",
            " [ 10   0   1   0   0   0  16]\n",
            " [154   0 135   4   0  15 359]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  42%|████▏     | 21/50 [08:22<11:42, 24.23s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:20,  2.73batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:16,  3.30batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:14,  3.67batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.88batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  3.97batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.13batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:11,  4.16batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:20,  2.26batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:21,  2.10batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:18,  2.47batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:15,  2.81batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:13,  3.15batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:12,  3.40batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:11,  3.64batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.81batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:09,  3.92batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:09,  3.96batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:13,  2.66batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:17,  2.05batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:14,  2.39batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:12,  2.76batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:10,  3.08batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:09,  3.33batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:08,  3.54batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:08,  3.73batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:07,  3.79batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:08<00:07,  3.91batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:08<00:06,  3.99batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:09<00:08,  3.20batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:12,  2.05batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:12,  1.98batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:10,  2.18batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:09,  2.32batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:11<00:08,  2.45batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:07,  2.54batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:07,  2.59batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:06,  2.61batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:08,  2.11batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:09,  1.77batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:07,  2.12batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:05,  2.49batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  2.85batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.19batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.45batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.66batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.83batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.95batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.98batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:03,  1.92batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.16batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.54batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.90batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.20batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.47batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.92batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Loss: 3.5276768375188112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  6.06batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.94batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.65batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.42batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.51batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.62batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.62batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  4.15batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:02,  2.12batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  2.57batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  3.07batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  3.55batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.01batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.99batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5456081081081081, F1 Score: 0.5359590935203461, AUC: 0.7225627583400024\n",
            "Confusion Matrix:\n",
            " [[551   0  37   0   0  13 136]\n",
            " [  6   0   1   0   0   0   5]\n",
            " [ 66   0  73   1   0  11 150]\n",
            " [  6   0   2   0   0   0  14]\n",
            " [  5   0   0   0   0   0   5]\n",
            " [  9   0   2   0   0   1  15]\n",
            " [151   0 154   2   0  16 344]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  44%|████▍     | 22/50 [08:45<11:08, 23.89s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  3.93batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:17,  3.11batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:18,  2.88batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:21,  2.44batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:23,  2.16batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:26,  1.89batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:03<00:34,  1.43batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:04<00:26,  1.79batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:04<00:21,  2.17batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:17,  2.56batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:15,  2.92batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:13,  3.23batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:12,  3.46batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:11,  3.65batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:10,  3.81batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:10,  3.76batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:10,  3.81batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:09,  3.87batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:09,  3.90batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:19,  1.82batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:15,  2.19batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:13,  2.54batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:11,  2.86batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:10,  3.17batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:09,  3.44batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.59batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.73batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:10,  2.65batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:11<00:13,  1.94batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:11,  2.26batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:09,  2.58batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:08,  2.88batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:07,  3.17batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:06,  3.38batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.60batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.73batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:04,  3.84batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.64batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:05,  2.85batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:07,  2.24batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:15<00:07,  1.95batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:07,  1.80batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:16<00:07,  1.72batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:05,  2.03batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:17<00:04,  2.41batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:17<00:03,  2.76batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:02,  3.01batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  3.29batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:18<00:01,  3.51batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:01,  3.72batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  3.88batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:01,  2.02batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  2.16batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:20<00:00,  2.55batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:20<00:00,  2.91batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.72batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Loss: 3.1676260847598314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.27batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.48batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.53batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.50batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.46batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.38batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.49batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.54batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.45batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  3.66batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:01,  2.25batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.72batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  3.15batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.98batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5456081081081081, F1 Score: 0.5316900203164565, AUC: 0.7200797499567161\n",
            "Confusion Matrix:\n",
            " [[560   0  29   0   0  12 136]\n",
            " [  6   0   1   0   0   0   5]\n",
            " [ 71   0  63   2   0   8 157]\n",
            " [  6   0   1   0   0   0  15]\n",
            " [  5   0   0   0   0   0   5]\n",
            " [  9   0   2   0   0   1  15]\n",
            " [162   0 139   6   0  15 345]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  46%|████▌     | 23/50 [09:10<10:49, 24.06s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.77batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.80batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.96batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:12,  4.05batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.09batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.10batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.15batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:16,  2.84batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:20,  2.28batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:20,  2.19batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:23,  1.89batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:24,  1.73batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:22,  1.85batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:18,  2.24batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:15,  2.62batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:13,  2.98batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:11,  3.28batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:10,  3.45batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:09,  3.66batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:09,  3.83batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:11,  3.09batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:16,  1.98batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:13,  2.30batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:11,  2.63batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:10,  2.97batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:08,  3.26batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.47batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:07,  3.70batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.81batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.95batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:05,  4.01batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:05,  4.04batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:07,  2.82batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:10,  2.01batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:08,  2.35batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:07,  2.64batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:06,  2.97batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:05,  3.23batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.48batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:04,  3.60batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.76batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.89batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:03,  3.97batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  2.87batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:04,  2.31batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:04,  2.04batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:04,  1.80batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:03,  1.80batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:02,  2.02batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.35batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.71batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.06batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  3.33batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.53batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Loss: 2.7049128878861666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.51batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.59batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.69batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.40batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.47batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.62batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:02,  3.23batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.25batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  2.74batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  3.22batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  3.67batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.11batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.48batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  4.02batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.545045045045045, F1 Score: 0.5346229187736112, AUC: 0.7256822469354555\n",
            "Confusion Matrix:\n",
            " [[546   0  36   2   0  11 142]\n",
            " [  4   0   1   0   0   0   7]\n",
            " [ 66   0  67   1   0  10 157]\n",
            " [  6   0   1   0   0   0  15]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  9   0   2   0   0   0  16]\n",
            " [146   0 150   2   0  14 355]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  48%|████▊     | 24/50 [09:33<10:19, 23.83s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.86batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.92batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.04batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:12,  4.07batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:28,  1.82batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:23,  2.11batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:19,  2.50batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:17,  2.81batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:15,  3.12batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.40batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.64batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.80batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:10,  3.93batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  4.00batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  4.06batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:09,  4.08batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:14,  2.69batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:16,  2.25batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:19,  1.93batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:19,  1.89batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:19,  1.76batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:16,  2.02batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:13,  2.41batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:11,  2.78batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:09,  3.10batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.36batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:08,  3.49batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.64batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:10,  2.62batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:12,  2.00batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:10,  2.39batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:08,  2.75batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:07,  3.07batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:06,  3.35batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.57batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.66batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.83batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.97batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  4.03batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:08,  1.85batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:06,  2.19batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:05,  2.54batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  2.87batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.17batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.44batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.64batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.79batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.92batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.95batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:02,  2.20batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.11batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.27batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.35batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.45batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.52batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 2.473503223620355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:04,  2.67batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:05,  2.11batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:07,  1.40batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:02<00:05,  1.79batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:03,  2.33batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  2.91batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  3.43batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  3.87batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  4.30batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:00,  4.62batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  4.85batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.01batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.16batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  3.43batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5489864864864865, F1 Score: 0.5350645130377548, AUC: 0.72028798770609\n",
            "Confusion Matrix:\n",
            " [[557   1  36   0   0   9 134]\n",
            " [  6   0   1   0   0   0   5]\n",
            " [ 73   0  63   1   0   7 157]\n",
            " [  6   0   1   0   0   0  15]\n",
            " [  5   0   0   0   0   0   5]\n",
            " [  9   0   1   0   0   0  17]\n",
            " [153   0 141   2   0  16 355]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  50%|█████     | 25/50 [09:57<09:59, 23.97s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.84batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.86batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.91batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:12,  4.01batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:21,  2.38batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:25,  1.93batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:21,  2.30batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:18,  2.67batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:15,  3.02batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.33batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.57batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.71batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.83batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  3.94batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.97batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:18,  2.21batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:18,  2.11batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:15,  2.45batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:13,  2.81batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:11,  3.14batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:11,  3.06batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:11,  2.95batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:11,  2.93batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:12,  2.59batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:14,  2.16batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:14,  2.09batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:15,  1.82batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:14,  1.87batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:12,  2.25batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:10,  2.58batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:08,  2.94batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:07,  3.24batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:06,  3.49batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:06,  3.62batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.80batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.89batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.98batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  4.01batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:08,  2.01batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:07,  2.18batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:05,  2.54batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:04,  2.88batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  3.15batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.39batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.63batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.81batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.91batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:01,  4.01batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  4.05batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  4.08batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  4.07batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:00,  4.07batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.29batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.16batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.55batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.92batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Loss: 2.2226810455322266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.22batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.33batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.39batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:02,  4.94batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  4.03batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  3.70batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  3.58batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.79batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  2.54batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:01,  2.27batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  1.82batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:01,  1.97batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  2.38batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.87batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.545045045045045, F1 Score: 0.5313155937655111, AUC: 0.7239698594085832\n",
            "Confusion Matrix:\n",
            " [[551   2  31   1   0   7 145]\n",
            " [  4   0   2   0   0   0   6]\n",
            " [ 70   1  58   1   1   6 164]\n",
            " [  6   0   1   0   0   0  15]\n",
            " [  5   0   0   0   0   0   5]\n",
            " [  9   0   1   0   0   0  17]\n",
            " [147   2 144   2   0  13 359]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  52%|█████▏    | 26/50 [10:22<09:38, 24.11s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.80batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.00batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.05batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.11batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.13batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.14batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.12batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.19batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:11,  4.17batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:24,  1.88batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:20,  2.23batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:16,  2.60batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:14,  2.95batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:12,  3.26batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:11,  3.46batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.66batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:10,  3.80batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:09,  3.93batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:05<00:09,  3.97batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:18,  1.97batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:15,  2.22batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:13,  2.54batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:11,  2.88batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:10,  3.18batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:07<00:08,  3.46batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:08,  3.64batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:07,  3.83batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:08<00:07,  3.57batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:08,  3.29batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:09<00:09,  2.70batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:11,  2.24batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:12,  1.89batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:13,  1.67batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:12,  1.83batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:09,  2.20batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:07,  2.57batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:06,  2.89batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:05,  3.20batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.48batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.68batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  3.76batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.89batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.99batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:02,  4.04batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:05,  1.87batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:04,  2.19batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:03,  2.51batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  2.86batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:02,  3.18batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.39batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.58batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  2.51batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  1.97batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.32batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.67batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.90batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Loss: 1.8952564322389662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.72batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.80batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.75batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.61batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.48batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.56batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.62batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.60batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.53batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  3.03batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:01,  2.47batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.11batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  1.91batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  3.11batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5394144144144144, F1 Score: 0.5300775633024215, AUC: 0.7230208201054642\n",
            "Confusion Matrix:\n",
            " [[536   2  36   0   2   9 152]\n",
            " [  4   1   1   0   0   0   6]\n",
            " [ 67   1  61   1   1   7 163]\n",
            " [  6   0   2   0   0   0  14]\n",
            " [  4   0   0   0   0   0   6]\n",
            " [  9   0   1   0   0   0  17]\n",
            " [135   2 155   1   0  14 360]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  54%|█████▍    | 27/50 [10:46<09:15, 24.16s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:20,  2.70batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:16,  3.27batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:14,  3.67batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.77batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  3.95batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:16,  3.01batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:24,  1.97batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:20,  2.34batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:16,  2.71batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:15,  3.00batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:13,  3.27batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:12,  3.47batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.64batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.78batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.90batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:09,  3.92batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:17,  2.17batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:17,  2.09batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:14,  2.41batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:12,  2.73batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:11,  3.02batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:09,  3.32batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:08,  3.57batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:08,  3.73batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:07,  3.81batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:07,  3.92batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:08<00:07,  3.99batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:06,  4.00batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:13,  1.99batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:11,  2.20batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:10,  2.32batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:09,  2.42batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:08,  2.53batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:08,  2.53batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:09,  2.12batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:10,  1.83batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:14<00:11,  1.57batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:08,  1.91batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:07,  2.27batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:05,  2.65batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:04,  3.00batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:03,  3.30batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.48batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  3.67batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:02,  3.83batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.92batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.92batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.97batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  4.06batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.09batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.00batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.32batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.63batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.97batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Loss: 1.58575957454741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.22batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.50batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.60batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.46batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.48batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.54batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.45batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.50batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.52batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  5.51batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  5.49batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:02<00:00,  5.48batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  2.23batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.97batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5501126126126126, F1 Score: 0.5347991396231023, AUC: 0.7271109484320473\n",
            "Confusion Matrix:\n",
            " [[548   2  28   1   0   8 150]\n",
            " [  5   1   1   0   0   0   5]\n",
            " [ 73   1  55   1   1   6 164]\n",
            " [  6   0   1   0   0   0  15]\n",
            " [  2   0   0   0   0   0   8]\n",
            " [  9   0   1   0   0   0  17]\n",
            " [148   2 129   1   1  13 373]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  56%|█████▌    | 28/50 [11:09<08:45, 23.91s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.93batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:17,  3.11batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:18,  2.94batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:18,  2.87batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:18,  2.80batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:18,  2.68batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:22,  2.15batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:32,  1.48batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:04<00:25,  1.83batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:20,  2.21batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:17,  2.59batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:15,  2.90batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:13,  3.21batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:12,  3.44batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:11,  3.66batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:10,  3.74batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:09,  3.91batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:09,  3.97batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:11,  3.09batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:17,  2.05batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:14,  2.40batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:12,  2.74batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:10,  3.08batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:09,  3.37batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:08,  3.55batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.74batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.83batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.89batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:06,  4.01batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:12,  2.14batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:11,  2.16batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:09,  2.52batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:08,  2.84batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:07,  3.11batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.39batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.65batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:04,  3.81batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:12<00:04,  3.91batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  4.02batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.43batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:06,  2.48batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:06,  2.09batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:06,  1.94batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:06,  1.85batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:06,  1.80batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:04,  2.19batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:03,  2.58batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  2.90batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  3.17batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.43batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  3.61batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  3.71batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.83batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.94batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  4.02batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.90batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 1.4291299595497549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:04,  2.65batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:05,  2.01batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:05,  2.11batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:03,  2.76batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.37batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  3.90batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  4.32batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  4.62batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  4.88batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  5.05batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  5.15batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.11batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.23batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  4.00batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5394144144144144, F1 Score: 0.5303555985053353, AUC: 0.716545766050502\n",
            "Confusion Matrix:\n",
            " [[546   6  32   2   2   7 142]\n",
            " [  5   1   1   0   0   0   5]\n",
            " [ 73   4  64   3   1   8 148]\n",
            " [  6   0   2   0   0   0  14]\n",
            " [  5   0   1   0   0   0   4]\n",
            " [ 10   0   2   0   0   0  15]\n",
            " [150   6 141   2   2  19 347]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  58%|█████▊    | 29/50 [11:34<08:23, 23.97s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.83batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.90batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.08batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.15batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.16batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.10batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.15batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.11batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:11,  4.10batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:02<00:12,  3.58batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:14,  3.02batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:17,  2.45batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:20,  2.06batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:22,  1.89batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:24,  1.66batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:20,  1.99batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:16,  2.37batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:13,  2.73batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:12,  3.07batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:10,  3.34batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:09,  3.58batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:09,  3.74batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:15,  2.06batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:14,  2.15batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:12,  2.49batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:10,  2.82batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:09,  3.12batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.37batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:07,  3.59batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.74batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.87batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:06,  3.97batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:10<00:05,  3.95batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:09,  2.25batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:09,  2.13batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:08,  2.44batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:06,  2.75batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:05,  3.09batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:05,  3.37batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.60batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  3.80batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.88batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.98batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:02,  4.03batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:14<00:02,  4.06batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  4.02batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:02,  4.03batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:15<00:02,  2.71batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:03,  2.19batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:03,  1.90batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:02,  1.74batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:02,  1.73batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.10batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.47batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.77batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Loss: 1.2527580023743212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.44batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.59batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.61batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.40batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.36batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.52batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.54batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.43batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:02,  2.06batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  2.51batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:01,  2.99batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  3.45batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  3.88batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.95batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.527027027027027, F1 Score: 0.5264230330208242, AUC: 0.7200476856710788\n",
            "Confusion Matrix:\n",
            " [[519  13  40   2   2   9 152]\n",
            " [  4   1   1   0   0   0   6]\n",
            " [ 57   6  67   4   1   8 158]\n",
            " [  5   0   2   0   0   1  14]\n",
            " [  2   0   0   0   0   0   8]\n",
            " [  8   0   2   0   0   1  16]\n",
            " [128  10 160   4   2  15 348]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  60%|██████    | 30/50 [11:57<07:55, 23.78s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  3.98batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  4.05batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:12,  4.08batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.10batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:27,  1.84batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:24,  2.07batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:19,  2.50batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:16,  2.89batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:15,  3.12batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.36batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.58batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.76batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.88batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  3.98batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  4.04batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:14,  2.70batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:17,  2.18batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:18,  2.09batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:20,  1.82batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:19,  1.86batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:16,  2.07batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:14,  2.32batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:12,  2.68batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:10,  3.03batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:09,  3.31batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.55batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.66batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.82batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:06,  3.90batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.98batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.99batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:11,  2.13batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:10,  2.23batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:08,  2.60batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:07,  2.93batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:06,  3.20batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.44batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.66batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.82batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.83batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  3.94batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  4.03batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  4.10batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:06,  1.84batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:05,  2.17batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:04,  2.48batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:03,  2.83batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.16batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:02,  3.39batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  3.58batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.72batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.87batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  3.88batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:17<00:00,  3.97batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  4.02batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  3.02batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31, Loss: 1.7665602485649288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:07,  1.73batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:06,  1.85batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:06,  1.77batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:02<00:05,  1.69batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:05,  1.62batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:03<00:03,  2.12batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:03<00:02,  2.63batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:01,  3.15batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  3.61batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:00,  4.05batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:00,  4.39batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  4.65batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  4.78batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  3.01batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5309684684684685, F1 Score: 0.525014475047783, AUC: 0.7108277005389894\n",
            "Confusion Matrix:\n",
            " [[562   3  33   0   0  22 117]\n",
            " [  4   1   3   0   0   1   3]\n",
            " [ 78   0  75   2   0  15 131]\n",
            " [  7   0   3   0   0   0  12]\n",
            " [  5   0   2   0   0   0   3]\n",
            " [ 10   0   4   0   0   0  13]\n",
            " [161   3 171   2   0  25 305]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  62%|██████▏   | 31/50 [12:21<07:36, 24.02s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.91batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.78batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.91batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  3.96batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:11,  4.03batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:11,  4.09batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:02<00:11,  4.10batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:02<00:10,  4.14batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:18,  2.43batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:20,  2.07batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:17,  2.40batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:15,  2.66batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:13,  2.99batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:11,  3.30batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:10,  3.55batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:05<00:10,  3.67batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:05<00:09,  3.81batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:08,  3.91batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:06<00:08,  4.01batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:06<00:10,  3.01batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:13,  2.31batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:15,  1.99batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:16,  1.84batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:16,  1.75batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:14,  1.94batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:11,  2.32batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:09,  2.68batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:08,  3.00batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:07,  3.24batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:06,  3.49batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:06,  3.62batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:11<00:05,  3.74batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:11<00:05,  3.85batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:09,  1.98batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:08,  2.14batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:06,  2.47batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:05,  2.78batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:04,  3.05batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:04,  3.27batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.47batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:03,  3.64batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  3.73batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.86batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:02,  3.96batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:03,  2.49batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:03,  2.11batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:02,  2.44batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  2.80batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.11batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  3.38batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.53batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  3.72batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.91batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, Loss: 8.444392317906022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:04,  2.83batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:03,  3.95batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:03,  3.58batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:02,  3.35batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.27batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  3.30batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  3.17batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  3.20batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  2.50batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:01,  2.24batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  2.31batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:01,  1.99batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  2.46batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.80batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.535472972972973, F1 Score: 0.5398572972045586, AUC: 0.7282324142307997\n",
            "Confusion Matrix:\n",
            " [[499   5  56   3   1  20 153]\n",
            " [  3   0   2   0   0   0   7]\n",
            " [ 48   3  86   2   1   8 153]\n",
            " [  5   1   3   0   0   0  13]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   8   0   0   0  11]\n",
            " [107   4 172   3   1  14 366]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  64%|██████▍   | 32/50 [12:46<07:15, 24.21s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.88batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.81batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.91batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:29,  1.77batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:25,  1.98batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:20,  2.44batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:17,  2.84batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:15,  3.12batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:13,  3.40batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:12,  3.61batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:11,  3.76batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.81batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:10,  3.92batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  3.97batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:14,  2.79batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:19,  2.08batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:16,  2.42batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:13,  2.77batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:11,  3.09batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:10,  3.35batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:09,  3.54batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:09,  3.71batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:08,  3.79batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:08,  3.90batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:07<00:07,  3.97batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:07,  3.97batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:08,  3.58batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:10,  2.68batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:12,  2.14batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:13,  1.88batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:14,  1.74batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:13,  1.73batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:11,  2.07batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:09,  2.42batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:07,  2.76batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:06,  3.09batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.34batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:05,  3.55batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.71batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.85batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  3.90batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:07,  1.84batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:05,  2.17batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:04,  2.55batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  2.89batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:03,  3.20batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.40batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.59batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.72batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.85batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.97batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.00batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.18batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.51batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.84batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.88batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 8.820361658930779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.56batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.67batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.63batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.62batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.48batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.42batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.50batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.51batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.39batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  4.16batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:01,  2.84batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.50batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  2.14batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  3.43batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5478603603603603, F1 Score: 0.5338792380695823, AUC: 0.7274318394177297\n",
            "Confusion Matrix:\n",
            " [[547   0  38   0   0  14 138]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 67   1  59   0   1   9 164]\n",
            " [  7   0   2   0   0   0  13]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [ 11   0   3   0   0   0  13]\n",
            " [160   1 124   0   1  14 367]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  66%|██████▌   | 33/50 [13:11<06:53, 24.31s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:15,  3.63batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.89batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.02batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.13batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.12batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:11,  4.17batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.13batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.14batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:11,  4.05batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:24,  1.89batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:20,  2.23batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:17,  2.57batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:14,  2.91batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:13,  3.15batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:12,  3.41batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:11,  3.57batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:10,  3.76batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:09,  3.81batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:05<00:09,  3.94batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:05<00:09,  4.00batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:12,  2.91batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:16,  2.08batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:13,  2.41batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:11,  2.76batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:07<00:10,  3.07batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:08,  3.35batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:08,  3.51batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:08<00:07,  3.68batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:08<00:07,  3.83batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:09<00:06,  3.91batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:09<00:06,  3.91batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:08,  2.70batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:10<00:09,  2.44batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:10,  2.14batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:11<00:11,  1.90batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:11,  1.79batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:09,  1.99batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:08,  2.21batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:06,  2.59batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:05,  2.92batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:04,  3.22batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:04,  3.46batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.66batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:03,  3.80batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:14<00:02,  3.79batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.92batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:15<00:02,  3.96batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:15<00:02,  3.32batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:03,  2.01batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:02,  2.38batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  2.76batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.09batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  3.35batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:17<00:00,  3.53batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  3.71batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  3.07batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Loss: 3.69849357008934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.44batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.58batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.41batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.49batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.53batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  3.04batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:03,  2.21batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.71batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  3.18batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  3.69batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  4.10batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.42batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.66batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.98batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5467342342342343, F1 Score: 0.5399967358228605, AUC: 0.7273836124808107\n",
            "Confusion Matrix:\n",
            " [[532   2  43   1   0  11 148]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 54   1  74   1   0   8 163]\n",
            " [  5   0   3   0   0   0  14]\n",
            " [  4   0   1   0   0   0   5]\n",
            " [  9   0   4   0   0   0  14]\n",
            " [136   1 149   1   0  15 365]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  68%|██████▊   | 34/50 [13:33<06:18, 23.67s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.81batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.99batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:17,  3.04batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:22,  2.31batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:24,  2.06batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:26,  1.86batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:03<00:29,  1.66batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:04<00:28,  1.68batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:04<00:22,  2.07batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:18,  2.46batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:15,  2.83batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:13,  3.17batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:12,  3.45batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:11,  3.67batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:10,  3.84batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:10,  3.94batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:09,  3.97batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:09,  3.97batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:09,  3.99batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:08,  4.04batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:08,  4.01batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:16,  2.09batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:14,  2.25batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:12,  2.62batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:10,  2.97batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:09,  3.19batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:08,  3.43batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.64batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:09<00:07,  3.77batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:12,  2.10batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:11,  2.09batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:09,  2.44batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:08,  2.77batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:07,  3.10batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.36batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.58batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.76batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.86batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.90batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  4.00batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:04,  3.02batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:06,  2.25batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:06,  1.97batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:06,  1.80batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:06,  1.81batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:17<00:04,  2.03batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:03,  2.36batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  2.69batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  3.03batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:01,  3.32batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  3.52batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  3.72batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.85batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.91batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  4.02batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.89batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35, Loss: 2.4243262400850654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:11,  1.09batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:07,  1.58batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:04,  2.32batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:03,  2.97batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.37batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  3.85batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  4.20batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  4.57batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  4.87batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  5.10batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  5.09batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.02batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  5.12batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.86batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5394144144144144, F1 Score: 0.5341868404182192, AUC: 0.7220133123670965\n",
            "Confusion Matrix:\n",
            " [[528   2  40   1   0  22 144]\n",
            " [  5   0   4   0   0   0   3]\n",
            " [ 60   1  63   1   1  11 164]\n",
            " [  6   0   4   0   0   0  12]\n",
            " [  4   0   1   0   0   0   5]\n",
            " [ 10   0   5   0   0   0  12]\n",
            " [133   5 143   0   1  18 367]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  70%|███████   | 35/50 [13:57<05:58, 23.88s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.88batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.80batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.92batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:12,  4.01batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.06batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.03batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:12,  4.08batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:12,  3.98batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:14,  3.28batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:02<00:15,  2.90batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:18,  2.43batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:20,  2.15batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:23,  1.87batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:22,  1.91batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:19,  2.11batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:17,  2.26batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:14,  2.62batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:12,  2.94batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:11,  3.20batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:10,  3.46batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:09,  3.66batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:12,  2.68batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:16,  1.99batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:13,  2.31batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:11,  2.65batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:10,  2.97batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:08,  3.26batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.45batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:07,  3.66batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.80batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:06,  3.93batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:08,  2.98batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:11,  1.99batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:09,  2.33batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:07,  2.64batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:06,  2.97batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.19batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:05,  3.45batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.64batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.79batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  3.91batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.98batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:05,  2.20batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:05,  2.12batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:04,  2.45batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:03,  2.57batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:03,  2.66batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  2.71batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  2.70batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:02,  2.73batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.17batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:19<00:02,  1.79batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  1.64batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:20<00:01,  1.99batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:20<00:00,  2.34batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.74batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Loss: 1.286148999352008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.37batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.48batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.54batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.36batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.41batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.43batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.49batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.57batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.55batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  2.10batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:01,  2.45batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.93batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  3.42batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.93batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5337837837837838, F1 Score: 0.530445359245377, AUC: 0.7248265164517781\n",
            "Confusion Matrix:\n",
            " [[527   3  45   2   0  18 142]\n",
            " [  4   0   4   0   0   0   4]\n",
            " [ 58   1  71   1   1  10 159]\n",
            " [  6   1   4   0   0   0  11]\n",
            " [  3   0   2   0   0   0   5]\n",
            " [  9   0   6   0   0   0  12]\n",
            " [136   3 166   1   1  10 350]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  72%|███████▏  | 36/50 [14:22<05:36, 24.02s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.68batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.79batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.86batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.88batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:13,  3.91batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  3.97batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:16,  2.91batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:23,  2.07batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:20,  2.26batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:17,  2.65batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:15,  2.99batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:13,  3.28batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:12,  3.43batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.67batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.85batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:11,  3.45batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:12,  3.18batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:14,  2.54batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:17,  2.12batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:18,  1.96batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:22,  1.54batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:18,  1.86batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:14,  2.22batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:12,  2.57batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:10,  2.92batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:09,  3.17batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:08,  3.44batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.62batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:07,  3.74batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.84batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:12,  1.93batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:11,  2.18batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:08,  2.56batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:07,  2.90batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.13batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.38batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:05,  3.60batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.73batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.81batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.91batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:06,  2.30batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:06,  2.10batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:05,  2.48batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:04,  2.79batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.11batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:02,  3.37batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.61batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.70batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.82batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.92batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  2.91batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.28batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  1.98batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:01,  1.79batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:20<00:00,  1.90batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.76batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Loss: 0.796864453703165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:03,  3.28batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:03,  3.62batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  4.20batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:02,  4.48batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:01,  4.68batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  3.78batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:03,  2.04batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.40batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  2.91batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:01,  3.39batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  3.82batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.18batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.45batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.65batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5365990990990991, F1 Score: 0.5292935678540094, AUC: 0.7244596905209092\n",
            "Confusion Matrix:\n",
            " [[528   3  39   2   0  19 146]\n",
            " [  4   0   3   0   0   0   5]\n",
            " [ 62   1  63   1   1  10 163]\n",
            " [  7   0   3   0   0   0  12]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [142   2 149   0   1  11 362]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  74%|███████▍  | 37/50 [14:46<05:14, 24.16s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.83batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.72batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:14,  3.78batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:23,  2.24batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:26,  1.94batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:20,  2.38batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:17,  2.74batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:15,  3.08batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:14,  3.35batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:12,  3.57batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.68batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.78batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.90batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  3.99batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:13,  3.02batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:19,  2.10batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:16,  2.38batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:14,  2.71batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:12,  2.89batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:12,  2.77batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:12,  2.80batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:12,  2.77batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:12,  2.72batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:14,  2.25batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:15,  2.00batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:16,  1.77batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:15,  1.85batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:12,  2.22batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:10,  2.55batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:08,  2.89batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:07,  3.20batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:06,  3.46batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:06,  3.65batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:05,  3.76batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.90batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:04,  4.02batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:05,  3.23batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:14<00:09,  1.99batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:07,  2.33batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:05,  2.68batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:05,  2.98batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:04,  3.27batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:03,  3.52batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.71batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  3.87batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:15<00:02,  3.97batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.97batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:01,  4.01batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  4.05batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:16<00:01,  4.05batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  1.90batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.23batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.56batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  2.88batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.20batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.91batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Loss: 0.6512835756875575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.54batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  4.06batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:03,  3.62batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:02,  3.39batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.31batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  3.31batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  2.51batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.23batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:03,  1.61batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:04<00:01,  2.04batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  2.50batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  2.99batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  3.43batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.90batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5382882882882883, F1 Score: 0.5335537786348364, AUC: 0.723308202202351\n",
            "Confusion Matrix:\n",
            " [[523   3  40   2   0  19 150]\n",
            " [  4   0   3   0   0   0   5]\n",
            " [ 58   1  67   1   1  10 163]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   4   0   0   0  15]\n",
            " [130   4 154   1   1  11 366]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  76%|███████▌  | 38/50 [15:10<04:50, 24.24s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.79batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.94batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.06batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:12,  4.01batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:27,  1.86batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:24,  2.08batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:19,  2.50batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:16,  2.91batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:14,  3.23batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.45batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.61batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:11,  3.76batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:14,  2.96batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:19,  2.18batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:22,  1.83batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:24,  1.65batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:07<00:26,  1.47batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:08<00:26,  1.43batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:08<00:24,  1.49batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:09<00:20,  1.74batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:09<00:18,  1.93batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:09<00:15,  2.13batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:10<00:14,  2.29batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:10<00:13,  2.43batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:11<00:13,  2.26batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:11<00:15,  1.95batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:12<00:16,  1.76batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:12<00:13,  2.10batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:12<00:10,  2.45batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:13<00:09,  2.80batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:13<00:08,  3.11batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:13<00:07,  3.30batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:13<00:06,  3.46batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:14<00:06,  3.64batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:14<00:05,  3.81batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:14<00:05,  3.69batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:15<00:09,  2.07batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:16<00:08,  2.12batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:16<00:06,  2.49batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:16<00:05,  2.83batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:16<00:04,  3.10batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:17<00:04,  3.35batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:17<00:03,  3.60batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:17<00:03,  3.77batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:18<00:05,  1.86batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:19<00:04,  2.17batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:19<00:03,  2.53batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:19<00:02,  2.82batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:19<00:02,  3.12batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:20<00:01,  3.38batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:20<00:01,  3.60batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:20<00:01,  3.78batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:20<00:00,  3.86batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:21<00:00,  3.89batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:21<00:00,  3.96batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:21<00:00,  2.61batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Loss: 0.5791896134614944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:04,  3.06batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:04,  2.67batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:05,  2.07batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:05,  1.89batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:05,  1.69batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:03<00:04,  1.61batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:03<00:03,  2.09batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:02,  2.55batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  3.05batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:04<00:01,  3.52batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:00,  3.94batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  4.32batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  4.52batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.90batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5427927927927928, F1 Score: 0.5325731770320593, AUC: 0.7250744785319169\n",
            "Confusion Matrix:\n",
            " [[536   2  39   2   0  13 145]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 62   1  60   1   1   8 168]\n",
            " [  7   0   3   0   0   0  12]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [143   3 142   1   1   9 368]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  78%|███████▊  | 39/50 [15:37<04:34, 24.95s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.76batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.91batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  4.03batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:00<00:12,  4.07batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.05batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:25,  1.96batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:22,  2.17batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:19,  2.50batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:16,  2.85batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:14,  3.16batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:13,  3.40batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:12,  3.62batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.80batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:10,  3.92batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  4.02batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.99batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:17,  2.18batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:18,  2.10batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:15,  2.45batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:12,  2.78batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:11,  3.10batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:10,  3.36batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:09,  3.54batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:08,  3.70batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:09,  3.35batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:10,  2.90batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:12,  2.32batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:14,  1.96batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:14,  1.83batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:15,  1.64batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:12,  2.00batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:10,  2.37batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:08,  2.71batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:07,  3.05batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.33batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.56batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:05,  3.65batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.80batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.88batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.96batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:13<00:03,  4.02batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.93batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:04,  2.86batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:05,  2.04batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:04,  2.37batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:03,  2.69batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:03,  3.00batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.28batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.55batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.72batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.78batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.88batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:17<00:00,  3.95batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.22batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  1.89batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.89batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Loss: 0.5531543206889182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.23batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.43batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.48batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.38batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.15batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.31batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.44batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.04batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:01,  4.25batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  3.90batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:01,  2.86batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.41batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  2.09batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  3.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5433558558558559, F1 Score: 0.5361368604403925, AUC: 0.7237335690919446\n",
            "Confusion Matrix:\n",
            " [[532   2  41   1   1  15 145]\n",
            " [  4   0   3   0   0   0   5]\n",
            " [ 59   1  65   1   1  10 164]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [136   4 147   1   1  10 368]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  80%|████████  | 40/50 [16:02<04:08, 24.87s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.82batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.82batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.95batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.94batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.01batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:22,  2.23batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:23,  2.09batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:19,  2.47batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:16,  2.79batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:14,  3.08batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:13,  3.35batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:12,  3.57batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.68batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:20,  2.08batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:19,  2.12batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:16,  2.48batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:13,  2.84batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:12,  3.14batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:10,  3.41batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:09,  3.63batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:09,  3.78batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:08,  3.85batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:08,  3.97batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:07,  4.03batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:10,  2.85batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:14,  2.06batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:12,  2.41batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:11,  2.52batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:10,  2.61batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:09,  2.65batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:09,  2.67batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:09,  2.65batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:10,  2.24batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:11,  1.92batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:13<00:13,  1.61batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:13<00:10,  1.97batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:08,  2.35batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:14<00:06,  2.73batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:05,  3.05batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:04,  3.28batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:04,  3.51batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.69batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:03,  3.85batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.93batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  3.98batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:04,  2.15batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:04,  2.16batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:03,  2.49batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  2.78batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.08batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  3.35batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  3.51batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.63batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.76batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.89batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.91batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Loss: 0.526739691151306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.20batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:01<00:08,  1.37batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:05,  1.89batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:03,  2.51batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  3.02batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  3.59batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:01,  4.06batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:01,  4.40batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  4.72batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:00,  4.95batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  5.05batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  5.14batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.28batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  3.49batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.535472972972973, F1 Score: 0.5285942565723389, AUC: 0.7223331786770777\n",
            "Confusion Matrix:\n",
            " [[537   2  40   2   0  17 139]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 64   1  69   1   1  10 155]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  9   0   3   0   0   0  15]\n",
            " [149   4 156   1   1  11 345]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  82%|████████▏ | 41/50 [16:26<03:42, 24.68s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:42,  1.30batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:38,  1.39batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:32,  1.63batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:02<00:24,  2.16batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:19,  2.63batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:16,  3.01batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:14,  3.32batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:13,  3.57batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:12,  3.76batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:11,  3.87batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:11,  3.92batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:11,  3.93batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:18,  2.33batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:20,  2.08batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:16,  2.41batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:14,  2.74batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:12,  3.04batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:11,  3.31batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:10,  3.56batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:09,  3.68batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:09,  3.82batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:08,  3.88batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:08,  3.91batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:08,  3.88batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:07,  3.97batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:08<00:07,  3.96batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:08<00:08,  3.42batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:13,  2.07batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:11,  2.35batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:09,  2.65batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:08,  2.93batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:07,  3.24batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:06,  3.42batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:11<00:06,  3.62batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:11<00:05,  3.75batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:11<00:05,  3.40batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:12<00:07,  2.63batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:08,  2.20batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:08,  1.94batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:08,  1.79batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:15<00:08,  1.70batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:06,  2.08batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:05,  2.45batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:04,  2.82batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:03,  3.12batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:03,  3.30batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.49batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.60batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:01,  3.76batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.81batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.92batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.46batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:01,  2.08batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.42batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.76batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.85batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42, Loss: 0.4823431825498119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.52batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.65batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:01,  5.63batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.40batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.33batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.44batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.42batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.44batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.14batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  2.26batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:01,  2.44batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.93batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  3.40batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.93batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.543918918918919, F1 Score: 0.5352102898439214, AUC: 0.7213573054081142\n",
            "Confusion Matrix:\n",
            " [[526   2  40   2   0  15 152]\n",
            " [  4   0   3   0   0   0   5]\n",
            " [ 60   1  60   1   1   9 169]\n",
            " [  7   0   3   0   0   0  12]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [133   4 139   1   1   9 380]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  84%|████████▍ | 42/50 [16:50<03:14, 24.35s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:13,  3.99batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.82batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.97batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.93batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.01batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:15,  3.13batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:22,  2.21batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:26,  1.83batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:27,  1.72batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:04<00:29,  1.57batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:04<00:23,  1.94batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:05<00:19,  2.30batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:16,  2.68batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:14,  2.99batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:12,  3.28batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:06<00:11,  3.48batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:10,  3.61batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:10,  3.66batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:09,  3.83batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:07<00:14,  2.51batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:17,  2.03batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:14,  2.36batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:12,  2.68batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:10,  3.00batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:09,  3.27batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.53batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.73batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:07,  3.81batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:06,  3.89batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:06,  3.84batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:12,  2.01batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:11,  2.16batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:09,  2.47batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:07,  2.77batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.09batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.38batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:05,  3.59batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.73batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.83batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.95batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:03,  3.95batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  4.02batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.48batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:04,  2.55batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:05,  2.06batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:05,  1.81batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:17<00:05,  1.75batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:04,  1.78batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:18<00:03,  2.14batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:18<00:02,  2.51batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:01,  2.86batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  3.18batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:00,  3.44batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  3.60batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.75batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Loss: 0.4839218673296273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.27batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.32batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.35batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.36batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.28batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.14batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:02,  2.50batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.33batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:02<00:01,  2.80batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:02<00:01,  3.28batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:03<00:00,  3.68batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  4.07batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  4.37batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.89batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5478603603603603, F1 Score: 0.5351393383393598, AUC: 0.722987687028418\n",
            "Confusion Matrix:\n",
            " [[540   1  38   2   0  12 144]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 65   1  59   1   1   6 168]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [148   2 133   0   1   9 374]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  86%|████████▌ | 43/50 [17:13<02:49, 24.15s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:15,  3.64batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.71batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.86batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:17,  3.04batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:29,  1.76batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:22,  2.19batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:19,  2.54batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:16,  2.90batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:14,  3.22batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.41batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.63batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:12,  3.42batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:13,  3.15batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:13,  3.05batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:14,  2.86batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:18,  2.20batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:20,  1.91batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:07<00:24,  1.52batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:19,  1.85batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:08<00:16,  2.21batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:13,  2.58batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:11,  2.88batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:10,  3.20batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:09,  3.41batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:08,  3.61batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:08,  3.72batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:07,  3.76batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:11,  2.49batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:11<00:13,  2.01batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:10,  2.39batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:09,  2.76batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:07,  3.09batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:06,  3.35batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:06,  3.55batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.71batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.77batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:05,  3.75batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.82batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.89batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:14<00:08,  1.96batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:06,  2.27batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:05,  2.65batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:04,  2.98batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:03,  3.28batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:03,  3.42batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:02,  3.60batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.75batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.86batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:16<00:01,  3.86batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.15batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.37batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.07batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  1.80batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:20<00:01,  1.72batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:20<00:00,  1.88batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:20<00:00,  2.72batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Loss: 0.4579414612380788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.28batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.33batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.22batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.25batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:00<00:01,  5.24batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:01,  5.34batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:01<00:01,  5.41batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:01<00:01,  5.24batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:01<00:00,  5.34batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:01<00:00,  5.27batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:02<00:00,  3.08batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:03<00:00,  2.25batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:03<00:00,  2.70batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:03<00:00,  3.86batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5444819819819819, F1 Score: 0.5331979007277482, AUC: 0.7213454322353848\n",
            "Confusion Matrix:\n",
            " [[540   1  38   2   0  14 142]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 64   1  60   1   1   7 167]\n",
            " [  7   0   3   0   0   0  12]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [147   2 141   0   1   9 367]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  88%|████████▊ | 44/50 [17:38<02:25, 24.27s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.78batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:13,  3.93batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.94batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.95batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.02batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.07batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:27,  1.75batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:22,  2.12batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:19,  2.46batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:16,  2.82batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:14,  3.15batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:12,  3.42batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.63batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.78batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.89batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:10,  3.88batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:10,  3.88batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:11,  3.40batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:15,  2.44batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:16,  2.23batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:18,  1.94batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:08<00:19,  1.78batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:19,  1.72batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:15,  2.10batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:09<00:12,  2.46batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:10,  2.83batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:09,  3.14batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:08,  3.40batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:07,  3.53batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:12,  2.16batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:12,  2.05batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:11<00:10,  2.39batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:08,  2.67batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:07,  3.01batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:06,  3.27batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:05,  3.52batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:05,  3.72batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:04,  3.79batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:04,  3.91batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.96batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:03,  3.95batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.93batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.96batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:15<00:04,  2.51batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:05,  2.04batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:04,  2.34batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:03,  2.68batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:02,  3.00batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  3.27batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.51batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.69batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.74batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.85batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.90batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:18<00:00,  3.93batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:18<00:00,  3.00batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Loss: 0.4414416855433956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:03,  3.31batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:05,  2.36batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:05,  1.85batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:02<00:05,  1.76batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:05,  1.71batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:03<00:05,  1.51batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:03<00:03,  1.97batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:02,  2.44batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:04<00:01,  2.95batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:04<00:01,  3.45batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:00,  3.83batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  4.21batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  4.51batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:05<00:00,  2.78batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5472972972972973, F1 Score: 0.5375024200427413, AUC: 0.7204002681103446\n",
            "Confusion Matrix:\n",
            " [[541   1  38   2   0  13 142]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 62   1  66   1   1   7 163]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [144   3 143   0   1  11 365]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  90%|█████████ | 45/50 [18:04<02:03, 24.74s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.85batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.83batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.94batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.91batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.02batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.11batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:01<00:11,  4.11batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:01<00:11,  4.04batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:02<00:11,  4.06batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:18,  2.51batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:22,  2.00batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:18,  2.35batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:15,  2.70batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:13,  3.00batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:12,  3.28batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:04<00:11,  3.51batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:05<00:10,  3.63batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:05<00:10,  3.75batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:05<00:09,  3.86batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:05<00:09,  3.93batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:06<00:08,  3.90batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:06<00:12,  2.75batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:14,  2.23batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:07<00:15,  2.12batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:15,  1.95batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:16,  1.82batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:09<00:15,  1.84batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:09<00:12,  2.19batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:10<00:10,  2.54batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:10<00:09,  2.86batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:10<00:07,  3.17batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:10<00:07,  3.38batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:11<00:06,  3.56batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:11,  1.84batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:10,  2.08batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:12<00:08,  2.41batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:06,  2.76batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:13<00:05,  3.05batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:13<00:05,  3.31batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:13<00:04,  3.51batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:14<00:04,  3.68batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:14<00:03,  3.79batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:14<00:03,  3.86batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:14<00:03,  3.95batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:15<00:02,  3.94batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:05,  1.82batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:04,  2.17batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:16<00:03,  2.54batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:02,  2.86batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.13batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:17<00:01,  3.31batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:17<00:01,  3.50batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:18<00:00,  3.65batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:18<00:00,  3.78batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  2.17batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.84batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Loss: 0.4249053552048281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:08,  1.61batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:05,  2.28batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:04,  2.62batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:03,  2.75batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:03,  2.85batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:02,  2.94batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  3.03batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:02,  2.57batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:04<00:02,  1.74batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:04<00:01,  2.15batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  2.64batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  3.14batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  3.62batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5461711711711712, F1 Score: 0.5366392078568586, AUC: 0.7197668247820835\n",
            "Confusion Matrix:\n",
            " [[536   1  40   1   1  14 144]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 62   1  63   1   1   7 166]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [139   4 143   1   1   8 371]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  92%|█████████▏| 46/50 [18:29<01:39, 24.85s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.79batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.75batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.90batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:13,  3.90batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:24,  2.12batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:26,  1.90batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:21,  2.31batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:18,  2.66batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:15,  3.02batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:13,  3.29batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:12,  3.51batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:03<00:12,  3.61batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:11,  3.72batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:17,  2.40batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:20,  1.99batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:17,  2.32batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:14,  2.65batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:12,  2.96batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:11,  3.23batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:10,  3.45batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:09,  3.56batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:09,  3.68batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:07<00:09,  3.31batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:11,  2.89batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:08<00:13,  2.24batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:09<00:14,  2.03batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:15,  1.83batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:11<00:17,  1.58batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:11<00:13,  1.94batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:11,  2.29batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:09,  2.65batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:12<00:08,  2.95batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:12<00:07,  3.22batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:12<00:06,  3.39batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:12<00:05,  3.60batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:13<00:05,  3.74batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:13<00:04,  3.82batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:14<00:10,  1.78batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:14<00:08,  2.09batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:15<00:06,  2.45batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:15<00:05,  2.77batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:15<00:04,  3.03batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:15<00:03,  3.27batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:16<00:03,  3.52batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:16<00:03,  3.66batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:16<00:02,  3.71batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:16<00:02,  3.82batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:17<00:02,  3.90batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:17<00:01,  3.97batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:17<00:01,  3.99batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:18<00:02,  2.03batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:18<00:01,  2.18batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:19<00:01,  2.54batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:19<00:00,  2.88batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:19<00:00,  3.13batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:19<00:00,  2.82batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Loss: 0.4044463459867984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.32batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:02,  5.43batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:00<00:02,  5.36batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:00<00:01,  5.36batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:01<00:02,  4.21batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:01<00:02,  2.98batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:02,  2.58batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:02<00:02,  2.27batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:02,  2.03batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:02,  1.93batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  1.90batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  2.37batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  2.87batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:04<00:00,  2.86batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5467342342342343, F1 Score: 0.5352982421135952, AUC: 0.7202290537831364\n",
            "Confusion Matrix:\n",
            " [[541   1  38   2   0  12 143]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 64   1  61   1   1   7 166]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   0   0   0   0   7]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [146   4 138   0   1   9 369]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  94%|█████████▍| 47/50 [18:54<01:14, 24.93s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.82batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:00<00:14,  3.73batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:00<00:13,  3.91batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:12,  4.01batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:01<00:12,  4.06batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:01<00:12,  4.04batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:28,  1.73batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:03<00:23,  2.07batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:19,  2.36batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:16,  2.71batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:14,  3.04batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:13,  3.24batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:04<00:12,  3.47batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:04<00:11,  3.63batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:04<00:10,  3.79batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:10,  3.80batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:18,  2.16batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:17,  2.12batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:06<00:15,  2.45batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:06<00:12,  2.80batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:07<00:11,  3.05batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:07<00:12,  2.68batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:08<00:13,  2.48batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:08<00:15,  2.00batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:10<00:28,  1.07batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:11<00:28,  1.06batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:12<00:28,  1.03batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:13<00:26,  1.07batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:14<00:22,  1.22batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:14<00:18,  1.40batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:15<00:15,  1.59batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:15<00:13,  1.82batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:15<00:10,  2.19batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:16<00:08,  2.55batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:16<00:08,  2.35batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:17<00:11,  1.71batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:17<00:09,  2.06batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:17<00:07,  2.40batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:18<00:06,  2.74batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:18<00:05,  3.06batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:18<00:04,  3.25batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:18<00:04,  3.43batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:19<00:03,  3.63batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:19<00:03,  3.78batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:19<00:02,  3.82batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:20<00:02,  3.89batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:20<00:03,  2.27batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:21<00:03,  2.12batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:21<00:02,  2.45batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:21<00:02,  2.78batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:22<00:01,  3.09batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:22<00:01,  3.17batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:22<00:01,  2.97batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:23<00:00,  2.92batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:23<00:00,  2.84batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:23<00:00,  2.34batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Loss: 0.3892659953562543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:01<00:16,  1.28s/batch]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:02<00:12,  1.07s/batch]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:02<00:09,  1.15batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:03<00:08,  1.23batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:04<00:06,  1.31batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:04<00:04,  1.75batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:04<00:03,  2.24batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:04<00:02,  2.76batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:05<00:01,  3.20batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:05<00:01,  3.61batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:05<00:00,  4.00batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:05<00:00,  4.35batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:05<00:00,  4.62batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:05<00:00,  2.35batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5399774774774775, F1 Score: 0.5314180799154646, AUC: 0.7189098368183865\n",
            "Confusion Matrix:\n",
            " [[532   1  41   2   0  15 146]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 64   1  63   1   1   7 164]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [140   4 148   1   1   9 364]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  96%|█████████▌| 48/50 [19:24<00:53, 26.52s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:00<00:14,  3.72batch/s]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:01<00:30,  1.76batch/s]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:01<00:32,  1.63batch/s]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:01<00:24,  2.11batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:02<00:19,  2.56batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:02<00:16,  2.95batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:02<00:14,  3.27batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:02<00:13,  3.52batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:03<00:12,  3.71batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:03<00:12,  3.68batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:03<00:11,  3.80batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:04<00:20,  2.18batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:05<00:19,  2.18batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:05<00:17,  2.42batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:05<00:14,  2.77batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:05<00:14,  2.80batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:06<00:14,  2.74batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:06<00:13,  2.74batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:07<00:15,  2.32batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:08<00:18,  1.94batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:08<00:19,  1.77batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:09<00:20,  1.66batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:09<00:16,  1.95batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:09<00:13,  2.30batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:10<00:11,  2.67batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:10<00:10,  2.96batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:10<00:08,  3.22batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:10<00:08,  3.41batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:11<00:07,  3.57batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:11<00:07,  3.58batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:11<00:07,  3.24batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:12<00:09,  2.65batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:13<00:10,  2.15batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:13<00:12,  1.76batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:14<00:12,  1.68batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:14<00:10,  1.92batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:15<00:09,  2.05batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:15<00:08,  2.14batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:16<00:07,  2.27batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:16<00:07,  2.09batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:17<00:10,  1.48batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:18<00:10,  1.35batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:19<00:10,  1.25batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:20<00:09,  1.20batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:21<00:09,  1.18batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:22<00:08,  1.21batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:22<00:06,  1.38batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:23<00:05,  1.59batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:23<00:03,  1.80batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:24<00:03,  1.66batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:24<00:03,  1.48batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:25<00:02,  1.83batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:25<00:01,  2.17batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:25<00:00,  2.34batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:26<00:00,  2.36batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:26<00:00,  2.12batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Loss: 0.38017458707327023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:04,  3.02batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:04,  2.99batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:04,  2.58batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:04,  2.39batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:04,  2.10batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:02<00:03,  2.21batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:02<00:03,  2.28batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:03<00:02,  2.49batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:03<00:01,  2.70batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:03<00:01,  2.85batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:04<00:01,  2.82batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:04<00:00,  2.94batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:04<00:00,  2.92batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:05<00:00,  2.74batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.545045045045045, F1 Score: 0.5368089041585835, AUC: 0.7170910252157737\n",
            "Confusion Matrix:\n",
            " [[526   1  40   1   1  12 156]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 60   1  65   1   2   7 165]\n",
            " [  6   0   4   0   0   0  12]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [131   4 145   1   1   8 377]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:  98%|█████████▊| 49/50 [19:56<00:28, 28.23s/it]\n",
            "Training:   0%|          | 0/56 [00:00<?, ?batch/s]\u001b[A\n",
            "Training:   2%|▏         | 1/56 [00:01<01:01,  1.12s/batch]\u001b[A\n",
            "Training:   4%|▎         | 2/56 [00:02<00:58,  1.09s/batch]\u001b[A\n",
            "Training:   5%|▌         | 3/56 [00:03<00:54,  1.03s/batch]\u001b[A\n",
            "Training:   7%|▋         | 4/56 [00:04<00:51,  1.02batch/s]\u001b[A\n",
            "Training:   9%|▉         | 5/56 [00:04<00:38,  1.33batch/s]\u001b[A\n",
            "Training:  11%|█         | 6/56 [00:04<00:28,  1.72batch/s]\u001b[A\n",
            "Training:  12%|█▎        | 7/56 [00:04<00:22,  2.14batch/s]\u001b[A\n",
            "Training:  14%|█▍        | 8/56 [00:05<00:18,  2.53batch/s]\u001b[A\n",
            "Training:  16%|█▌        | 9/56 [00:05<00:16,  2.88batch/s]\u001b[A\n",
            "Training:  18%|█▊        | 10/56 [00:05<00:14,  3.15batch/s]\u001b[A\n",
            "Training:  20%|█▉        | 11/56 [00:05<00:13,  3.42batch/s]\u001b[A\n",
            "Training:  21%|██▏       | 12/56 [00:06<00:12,  3.59batch/s]\u001b[A\n",
            "Training:  23%|██▎       | 13/56 [00:06<00:13,  3.28batch/s]\u001b[A\n",
            "Training:  25%|██▌       | 14/56 [00:07<00:16,  2.61batch/s]\u001b[A\n",
            "Training:  27%|██▋       | 15/56 [00:07<00:17,  2.32batch/s]\u001b[A\n",
            "Training:  29%|██▊       | 16/56 [00:08<00:18,  2.12batch/s]\u001b[A\n",
            "Training:  30%|███       | 17/56 [00:08<00:20,  1.95batch/s]\u001b[A\n",
            "Training:  32%|███▏      | 18/56 [00:09<00:20,  1.86batch/s]\u001b[A\n",
            "Training:  34%|███▍      | 19/56 [00:09<00:16,  2.24batch/s]\u001b[A\n",
            "Training:  36%|███▌      | 20/56 [00:09<00:13,  2.59batch/s]\u001b[A\n",
            "Training:  38%|███▊      | 21/56 [00:10<00:11,  2.93batch/s]\u001b[A\n",
            "Training:  39%|███▉      | 22/56 [00:10<00:10,  3.11batch/s]\u001b[A\n",
            "Training:  41%|████      | 23/56 [00:10<00:09,  3.36batch/s]\u001b[A\n",
            "Training:  43%|████▎     | 24/56 [00:10<00:09,  3.48batch/s]\u001b[A\n",
            "Training:  45%|████▍     | 25/56 [00:11<00:08,  3.46batch/s]\u001b[A\n",
            "Training:  46%|████▋     | 26/56 [00:11<00:09,  3.23batch/s]\u001b[A\n",
            "Training:  48%|████▊     | 27/56 [00:12<00:16,  1.76batch/s]\u001b[A\n",
            "Training:  50%|█████     | 28/56 [00:13<00:16,  1.67batch/s]\u001b[A\n",
            "Training:  52%|█████▏    | 29/56 [00:14<00:18,  1.45batch/s]\u001b[A\n",
            "Training:  54%|█████▎    | 30/56 [00:14<00:17,  1.48batch/s]\u001b[A\n",
            "Training:  55%|█████▌    | 31/56 [00:15<00:14,  1.70batch/s]\u001b[A\n",
            "Training:  57%|█████▋    | 32/56 [00:16<00:17,  1.40batch/s]\u001b[A\n",
            "Training:  59%|█████▉    | 33/56 [00:16<00:14,  1.58batch/s]\u001b[A\n",
            "Training:  61%|██████    | 34/56 [00:17<00:12,  1.73batch/s]\u001b[A\n",
            "Training:  62%|██████▎   | 35/56 [00:17<00:12,  1.64batch/s]\u001b[A\n",
            "Training:  64%|██████▍   | 36/56 [00:18<00:13,  1.50batch/s]\u001b[A\n",
            "Training:  66%|██████▌   | 37/56 [00:19<00:13,  1.41batch/s]\u001b[A\n",
            "Training:  68%|██████▊   | 38/56 [00:19<00:10,  1.65batch/s]\u001b[A\n",
            "Training:  70%|██████▉   | 39/56 [00:20<00:11,  1.52batch/s]\u001b[A\n",
            "Training:  71%|███████▏  | 40/56 [00:21<00:09,  1.62batch/s]\u001b[A\n",
            "Training:  73%|███████▎  | 41/56 [00:21<00:08,  1.77batch/s]\u001b[A\n",
            "Training:  75%|███████▌  | 42/56 [00:22<00:07,  1.87batch/s]\u001b[A\n",
            "Training:  77%|███████▋  | 43/56 [00:22<00:06,  1.97batch/s]\u001b[A\n",
            "Training:  79%|███████▊  | 44/56 [00:22<00:05,  2.19batch/s]\u001b[A\n",
            "Training:  80%|████████  | 45/56 [00:23<00:04,  2.56batch/s]\u001b[A\n",
            "Training:  82%|████████▏ | 46/56 [00:23<00:03,  2.52batch/s]\u001b[A\n",
            "Training:  84%|████████▍ | 47/56 [00:24<00:05,  1.69batch/s]\u001b[A\n",
            "Training:  86%|████████▌ | 48/56 [00:24<00:03,  2.02batch/s]\u001b[A\n",
            "Training:  88%|████████▊ | 49/56 [00:25<00:02,  2.35batch/s]\u001b[A\n",
            "Training:  89%|████████▉ | 50/56 [00:25<00:02,  2.69batch/s]\u001b[A\n",
            "Training:  91%|█████████ | 51/56 [00:25<00:01,  2.97batch/s]\u001b[A\n",
            "Training:  93%|█████████▎| 52/56 [00:25<00:01,  3.25batch/s]\u001b[A\n",
            "Training:  95%|█████████▍| 53/56 [00:26<00:00,  3.46batch/s]\u001b[A\n",
            "Training:  96%|█████████▋| 54/56 [00:26<00:00,  3.64batch/s]\u001b[A\n",
            "Training:  98%|█████████▊| 55/56 [00:26<00:00,  3.76batch/s]\u001b[A\n",
            "Training: 100%|██████████| 56/56 [00:26<00:00,  2.10batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 0.3750708518200554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Validation:   0%|          | 0/14 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation:   7%|▋         | 1/14 [00:00<00:02,  5.08batch/s]\u001b[A\n",
            "Validation:  14%|█▍        | 2/14 [00:00<00:03,  3.91batch/s]\u001b[A\n",
            "Validation:  21%|██▏       | 3/14 [00:01<00:04,  2.43batch/s]\u001b[A\n",
            "Validation:  29%|██▊       | 4/14 [00:01<00:05,  1.80batch/s]\u001b[A\n",
            "Validation:  36%|███▌      | 5/14 [00:02<00:06,  1.33batch/s]\u001b[A\n",
            "Validation:  43%|████▎     | 6/14 [00:03<00:06,  1.28batch/s]\u001b[A\n",
            "Validation:  50%|█████     | 7/14 [00:04<00:04,  1.43batch/s]\u001b[A\n",
            "Validation:  57%|█████▋    | 8/14 [00:04<00:03,  1.57batch/s]\u001b[A\n",
            "Validation:  64%|██████▍   | 9/14 [00:05<00:02,  1.72batch/s]\u001b[A\n",
            "Validation:  71%|███████▏  | 10/14 [00:05<00:01,  2.14batch/s]\u001b[A\n",
            "Validation:  79%|███████▊  | 11/14 [00:05<00:01,  2.61batch/s]\u001b[A\n",
            "Validation:  86%|████████▌ | 12/14 [00:05<00:00,  3.12batch/s]\u001b[A\n",
            "Validation:  93%|█████████▎| 13/14 [00:06<00:00,  3.60batch/s]\u001b[A\n",
            "Validation: 100%|██████████| 14/14 [00:06<00:00,  2.24batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5456081081081081, F1 Score: 0.5333763300178103, AUC: 0.7180435330867385\n",
            "Confusion Matrix:\n",
            " [[542   1  37   1   1  13 142]\n",
            " [  5   0   3   0   0   0   4]\n",
            " [ 69   1  59   1   1   7 163]\n",
            " [  7   0   4   0   0   0  11]\n",
            " [  3   0   1   0   0   0   6]\n",
            " [  8   0   3   0   0   0  16]\n",
            " [149   4 137   0   1   8 368]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 50/50 [20:30<00:00, 24.60s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆███▇▇▆▆▆▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>auc</td><td>▁▇██▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▅▅▄▅▄▄▅▅▅▄▅▅▅▄▄▄▄▄▄▄▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>f1_score</td><td>▁▇███▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>loss</td><td>██▇▆▆▅▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54561</td></tr><tr><td>auc</td><td>0.71804</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>f1_score</td><td>0.53338</td></tr><tr><td>loss</td><td>0.37507</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">distinctive-music-40</strong> at: <a href='https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project/runs/fffdukge' target=\"_blank\">https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project/runs/fffdukge</a><br> View project at: <a href='https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project' target=\"_blank\">https://wandb.ai/eabu2ss-metu-middle-east-technical-university/IS%20584%20Course%20Term%20Project</a><br>Synced 5 W&B file(s), 50 media file(s), 0 artifact file(s) and 50 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>outputs/wandb/run-20250524_135409-fffdukge/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zipping folders to download"
      ],
      "metadata": {
        "id": "goMRpxpuqaGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zip_folder(folder_path, zip_name):\n",
        "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(full_path, start=folder_path)  # path inside zip\n",
        "                zipf.write(full_path, arcname)\n",
        "zip_folder('checkpoints', 'checkpoints.zip')\n",
        "zip_folder('outputs', 'outputs.zip')"
      ],
      "metadata": {
        "id": "0OJBs1q9pTs0"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}